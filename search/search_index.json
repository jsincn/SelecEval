{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction","text":""},{"location":"#abstract","title":"Abstract","text":"<p>With the increasing demand for privacy-preserving machine learning, Federated Learning has emerged as a technique for decentralized training. It enables clients to train locally and share their updates with the other clients in the federation. This negates the need to transmit raw data to a centralized server while still benefitting from training on data collected by all clients. Due to practical constraints, training all clients is usually not feasible. Furthermore, clients are usually heterogeneous, with different capabilities and collected data. Numerous approaches have been developed to select clients for participation in each training round effectively. However, no clear comparison exists between the different strategies and approaches in a unified scenario. This thesis presents SelecEval, a comprehensive simulator for evaluating client selection approaches. SelecEval includes a robust simulation of client and data heterogeneity as well as extensive analytics tools to enable a detailed comparison between different approaches. It also includes reference implementations of common selection strategies and is modular, allowing quick integration of new datasets, simulation components, and strategies for comparison.</p>"},{"location":"#starting-a-simulation","title":"Starting a simulation","text":"<p>To start a simulation execute the following command:</p> <pre><code>python -m seleceval.run config.json\n</code></pre>"},{"location":"config/","title":"Configuration","text":""},{"location":"config/#introduction","title":"Introduction","text":"<p>When starting the program a config file <code>config.json</code> is passed to the application. It defines the core execution parameters.</p>"},{"location":"config/#attributes-and-values","title":"Attributes and values","text":"<p>The following table lists all attributes and their possible values.</p> Key optional Description Min Max Default Value Example Value no_rounds no Number of rounds to run the simulation for 1 - - 10 algorithm no List of algorithms to simulate - - - <code>[\"PowD\", \"FedCS\", \"random\", \"ActiveFL\", \"CEP\"]</code> alogrithm_config yes Algorithm configuration - - - See algorithm documentation no_epochs yes Number of epochs to run on each client per round 1 - 1 1 no_clients no Number of clients to simulate 1 - - 1000 batch_size yes Batch size, will affect behavior of training and validation. Can lead to errors with batchnorm, etc. if changed 1 - 32 32 verbose yes Enables additional logging - - <code>true</code> <code>true</code> or <code>false</code> device yes Pytorch device string - - <code>cpu</code> <code>cpu</code> or <code>cuda</code> num_cpu_per_client yes Number of CPU cores to assign to each client. Integer. 1 CPU_COUNT 2 2 num_gpu_per_client yes Number of GPU resources to assign to each client. Only used if <code>device</code> is set to <code>cuda</code>. Partial allocation is possible. 0 - 0.1 0.1 timeout no Timeout imposed on clients, in seconds. This affects only the simulation. 1 - - 60 generate_client_states yes Whether to generate new client states when running the simulation. If <code>False</code> is selected, errors may occur if not enough states are predefined. - - <code>true</code> <code>true</code> or <code>false</code> client_state_file no File to use for client states. Will be overwritten if generate_client_states is <code>True</code>. - - - <code>client_states.csv</code> distribute_data yes Whether to regenerate the data distribution. - - <code>true</code> <code>true</code> or <code>false</code> data_distribution_file no File containing an existing data distribution, not used when distribute_data is  <code>True</code> - - - <code>data_distribution.csv</code> output_dir no Folder prefix to use for output. Will not be overwritten. - - - <code>output</code> client_configuration_file no File that contains the available client configurations. See documentation on Client Configuration. - - - <code>client_configurations.csv</code> max_workers yes Maximum number of workers that should be used when running distributed tasks. (May not always be enforced) - - 32 32 data_config yes Configuration for data skew, distortion - - - See data configuration validation_config yes Configuration of the final validation runs - - - See validation configuration simulation_config yes Configuration relating to performance, reliability and network bandwidth of clients - - - See simulation configuration base_strategy yes Base strategy to use for aggregation - - <code>FedAvg</code> <code>FedAvg</code>, <code>FedAvgM</code>, <code>FedMedian</code>"},{"location":"installation/","title":"Installation","text":"<p>Clone this repo. </p> <pre><code>git clone https://github.com/jsincn/SelecEval.git\ncd seleceval\n</code></pre> <p>Create a new virtual environment and install dependencies.</p> <pre><code>python -m venv seleceval\nsource seleceval/bin/activate\npip install --upgrade pip\npip install -r requirements.txt\n</code></pre>"},{"location":"thesis/","title":"Thesis","text":"<p>This project was completed as a thesis project at the  Chair of Robotics, Artificial Intelligence and Real-time Systems at the Technical University of Munich.</p> <p>As such there are two main branches included in this repository: </p> <ul> <li>The branch <code>thesis</code> contains the code as it was during the execution of the experiments for the thesis</li> <li>The branch <code>master</code> contains the latest version of the code.</li> </ul> <p>For reproducing the results from the thesis, please use the <code>thesis</code> branch.  However, it may contain bugs and is not updated.</p> <p>The configuration files used for the experiments are included in the Examples Section.</p>"},{"location":"algorithms/active/","title":"ActiveFL","text":"<p>ActiveFL is an algorithm introduced in 2019 with the goal of selecting an optimized subset of clients to participate in federated learning based on a value function. This value function aims to quantify the expected usefulness of a client\u2019s data during a training round. In addition to sampling a subset of the clients based on their valuation, another set is selected uniformly at random. While not explicitly mentioned in the original paper we assume that the random portion of the sampled set aims to reduce overfitting on the same clients every round.</p> <p>It is based on the paper  <pre><code>Goetz, Jack, Kshitiz Malik, D. Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar. 2019. \n\u201cActive Federated Learning.\u201d arXiv.org. \nhttps://www.semanticscholar.org/paper/36b9b82b607149f160abde58db77149c6de58c01.\n</code></pre> The algorithm may be selected by choosing <code>ActiveFL</code> as the algorithm in the config file.</p> <p>It requires the following parameters:</p> Key Description Example Value c Describes the share of all clients to participate in the round 0.2 alpha1 Percentage of lowest score clients to disqualify 0.75 alpha2 Parameter for selection probability 0.01 alpha3 Percentage of clients to select randomly 0.1"},{"location":"algorithms/cep/","title":"CEP","text":"<p>The client eligibility protocol for federated learning was introduced by Asad et al. in 2022. The core idea of this strategy is to select clients based on their performance in 16 4 Implementation previous communication rounds. For this, a subset of clients is initially selected that fulfills the performance requirements. In addition, all clients are given an initial client eligibility score (CES) of 75. Then, based on their previous round performance, they are rewarded or penalized. In our implementation of CEP, each client is rewarded 10 points for successful participation and punished by 5 points if it fails due to a timeout. If a client failed the previous five rounds in a row, they will be penalized by an additional \u221220 Points. Due to different implementation constraints between the simulation used by Asad et al. and our simulator, we could not implement the full original algorithm. However, our adjusted variant achieves respectable results, in line with those achieved in the original paper. </p> <p>It is based on the paper  <pre><code>Asad, Muhammad, Safa Otoum, and Saima Shaukat. 2022. \n\u201cResource and Heterogeneity-Aware Clients Eligibility Protocol in Federated Learning.\u201d \nIn GLOBECOM 2022 - 2022 IEEE Global Communications Conference, 1140\u201345.\n</code></pre> The algorithm may be selected by choosing <code>CEP</code> as the algorithm in the config file.</p> <p>It requires the following parameters:</p> Key Description Example Value c Describes the share of all clients to participate in the round 0.2"},{"location":"algorithms/fedcs/","title":"FedCS","text":"<p>FedCS aims to optimize the number of clients involved in each round. It does so by greedily selecting the largest number of clients that can feasibly complete the round of training. This reduces the number of clients that participate, but fail to contribute to the global model in each round.</p> <p>It is based on the paper  <pre><code>Client Selection for Federated Learning with Heterogeneous Resources in Mobile Edge.\nNishio, Takayuki, and Ryo Yonetani. 2018. arXiv [cs.NI]. arXiv. https://arxiv.org/abs/1804.08333.\n</code></pre> The algorithm may be selected by choosing <code>FedCS</code> as the algorithm in the config file.</p> <p>It requires the following parameters:</p> Key Description Example Value pre_sampling Describes the percentage of the total available client to select for participation in client selection. If set to 0 disable preselection. 0.2 fixed_client_no Whether the client number should be fixed or not (useful for comparison) <code>True</code> or <code>False</code> c Describes the share of all clients to participate in the round (only if <code>fixed_client_no</code> is <code>True</code>) 0.2"},{"location":"algorithms/powd/","title":"Pow-D","text":"<p>The PowD client selection strategy proposed by Cho et. al. in 2020 is based on sampling the clients with the highest local loss. Based on their convergence analysis this results in an increased convergence rate compared to unbiased client selection. In their own testing, they achieved 3\u00d7 higher convergence speed as well as up to 10% higher accuracy compared to random selection. We elected to use the computation efficient variant $\\pi_{cpow-d}$ which uses a randomly sampled subset to estimate the client loss. For this, we used the client\u2019s validation set, as this is randomly sampled from a client\u2019s assigned training samples.</p> <p>It is based on the paper  <pre><code>Client Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies.\nCho, Yae Jee, Jianyu Wang, and Gauri Joshi. 2020. arXiv.org. https://www.semanticscholar.org/paper/e245f15bdddac514454fecf32f2a3ecb069f6dec.\n</code></pre> The algorithm may be selected by choosing <code>PowD</code> as the algorithm in the config file. As a note, the algorithm as it is implemented in this context runs the validation on the entire validation set, rather than micro batches.</p> <p>It requires the following parameters:</p> Key Description Example Value pre_sampling Describes the share of all clients that should be selected to calculate their losses 0.4 c Describes the share of all clients that should be selected 0.2"},{"location":"algorithms/random/","title":"Random","text":"<p>The simplest selection strategy is random selection. It was first introduced along with federated learning itself in 2016. It is still the most frequently used strategy due to its simplicity and good results. The core parameter for this strategy is c, which is the percentage of available clients to select for a particular learning round. Common values for c range between 10% and 20%, depending on the total number of available clients.</p> <p>It is based on the paper  <pre><code>McMahan, H. Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag\u00fcera y. Arcas. 2016. \n\u201cCommunication-Efficient Learning of Deep Networks from Decentralized Data.\u201d \narXiv [cs.LG]. arXiv. http://arxiv.org/abs/1602.05629.\n</code></pre> The algorithm may be selected by choosing <code>random</code> as the algorithm in the config file.</p> <p>It requires the following parameters:</p> Key Description Example Value c Describes the share of all clients to participate in the round 0.2"},{"location":"data/adding_new_data_distributions/","title":"Adding new data distributions","text":"<p>The process for adding new data distributions is as follows and identical for feature, label and quantity skews:</p> <ol> <li>Inside the <code>seleceval/datahandler</code> directory, select the appropriate subdirectory for feature, label or quantity distributions</li> <li>Create a new python file for your distribution and inherit from the appropriate base class</li> <li>Implement the appropriate methods</li> <li>Add the new distribution to the <code>__init__.py</code> file in the same directory</li> <li>Add the new distribution to appropriate <code>seleceval/util/config_parameters</code> file, including any relevant parameters</li> </ol> <p>You can use the existing distributions as a template for your own.</p>"},{"location":"data/datasets/CIFAR10/","title":"CIFAR10","text":"<p>We include the CIFAR-10 dataset, which is frequently used in literature and considered a standard deep learning dataset. CIFAR-10 consists of 50,000 training and 10,000 test images, split into ten classes of 6000 32x32 pixel images each.</p>"},{"location":"data/datasets/CIFAR10/#example-data","title":"Example Data","text":"<pre><code>Krizhevsky, Alex, Geoffrey Hinton, and Others. 2009. \n\u201cLearning Multiple Layers of Features from Tiny Images.\u201d\n</code></pre>"},{"location":"data/datasets/MNIST/","title":"MNIST","text":"<p>We integrated the MNIST dataset into the tool. The MNIST dataset consists of 70,000 handwritten digits, split into 10,000 test and 60,000 training images. We included the MNIST dataset to enable quicker testing, as the complexity is significantly lower than CIFAR-10.</p>"},{"location":"data/datasets/MNIST/#example-data","title":"Example Data","text":"<pre><code>LeCun, Yann, Corinna Cortes, and C. J. Burges. n.d. \n\u201cMNIST Handwritten Digit Database.\u201d \nATT Labs [Online]. Available: Http://yann.Lecun.Com/exdb/mnist.\n</code></pre>"},{"location":"data/datasets/adding_new_datasets/","title":"Adding new datasets","text":"<p>Adding new datasets to SelecEval can easily be done.  The following steps are required:</p> <ol> <li>Create a new class in the seleceval/datahandler directory that inherits from the DataHandler class.</li> <li>Implement the <code>load_distributed_datasets()</code> and the <code>get_classes()</code> methods</li> </ol> <p>The <code>load_distributed_datasets()</code> method returns a list of trainloaders, validationloaders and the testloader. You may use the <code>split_and_transform_data()</code> method to split the data into the different loaders  based on the existing distribution strategies. You can also manually create the split should your dataset already contain metadata based on which you wish to allocate the date to the different clients.</p> <p>The <code>get_classes()</code> method returns a tuple of the classes in the dataset.</p>"},{"location":"data/feature_distributions/gaussian/","title":"Gaussian","text":"<p>In a real-world federated learning setting, feature skew could be caused by regional differences between the clients and different sensor characteristics.  As the simulator focuses on computer vision applications, specific Gaussian noise may be added to each client\u2019s data to simulate this feature skew.</p>"},{"location":"data/feature_distributions/gaussian/#parameters","title":"Parameters","text":"Key Description Example Value data_feature_skew_mu Mean for feature skew 0 data_feature_skew_std Standard deviation for feature skew 1"},{"location":"data/label_distributions/dirichlet/","title":"Dirichlet","text":"<p>The Dirichlet-based distribution uses a Dirichlet distribution to determine the share of each label for every client. The distribution parameter \u03b1 is customizable by the user. Following related literature, a default value of \u03b1 = 0.5 is set.</p>"},{"location":"data/label_distributions/dirichlet/#parameters","title":"Parameters","text":"Key Description Example Value data_label_distribution_parameter Minimum number of samples to assign to each client 1 <p>Based on: <pre><code>Li, Qinbin, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. \n\u201cFederated Learning on Non-IID Data Silos: An Experimental Study.\u201d \nIn 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE. \nhttps://doi.org/10.1109/icde53745.2022.00077.\n</code></pre> <pre><code>Hsu, Tzu-Ming Harry, Hang Qi, and Matthew Brown. 2019. \n\u201cMeasuring the Effects of Non-Identical Data Distribution for Federated Visual Classification.\u201d \narXiv [cs.LG]. arXiv. http://arxiv.org/abs/1909.06335.\n</code></pre></p>"},{"location":"data/label_distributions/discrete/","title":"Discrete","text":"<p>Discrete distribution is a type of label distribution. In this case, every client is only allocated data from a subset of the available classes. This technique is included as it is widely used in literature. However, due to the very extreme nature of this partitioning, this may not be entirely realistic. The user may select the number of classes assigned to each client.</p>"},{"location":"data/label_distributions/discrete/#parameters","title":"Parameters","text":"Key Description Example Value data_label_class_quantity Number of classes to allocate to each client 2 <p>Based on <pre><code>McMahan, H. Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag\u00fcera y. Arcas. 2016. \n\u201cCommunication-Efficient Learning of Deep Networks from Decentralized Data.\u201d \narXiv [cs.LG]. arXiv. http://arxiv.org/abs/1602.05629.\n</code></pre> <pre><code>Yu, Felix X., Ankit Singh Rawat, Aditya Krishna Menon, and Sanjiv Kumar. 2020. \n\u201cFederated Learning with Only Positive Labels.\u201d \narXiv [cs.LG]. arXiv. http://arxiv.org/abs/2004.10342.\n</code></pre> <pre><code>Li, Qinbin, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. \n\u201cFederated Learning on Non-IID Data Silos: An Experimental Study.\u201d \nIn 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE. \nhttps://doi.org/10.1109/icde53745.2022.00077.\n</code></pre></p>"},{"location":"data/label_distributions/uniform/","title":"Uniform","text":"<p>When using the uniform distribution, every client is allocated the same number of samples of each class. This leads to better training convergence, as the data is now i.i.d., however, this is not realistic for a real-world FL scenario.</p>"},{"location":"data/quantity_distributions/dirichlet/","title":"Dirichlet","text":"<p>The second type is a Dirichlet distribution that allocates a different number of samples to each client. In this case, each client receives a different percentage of the whole dataset. In total, the number of samples distributed is equal to the length of the dataset. Once again, samples are selected with replacement from the entire training set. </p>"},{"location":"data/quantity_distributions/dirichlet/#parameters","title":"Parameters","text":"Key Description Example Value data_quantity_skew_parameter_1 Parameter 1 for the dirichlet distribution 0.5 data_quantity_skew_parameter_2 Parameter 2 for the dirichlet distribution 5.0 data_quantity_min_parameter Minimum number of samples to assign to each client 1 data_quantity_max_parameter Maximum number of samples to assign to each client 1000"},{"location":"data/quantity_distributions/dirichlet/#example-distributions","title":"Example distributions","text":"<p>Adapted from: <pre><code>Li, Qinbin, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. \n\u201cFederated Learning on Non-IID Data Silos: An Experimental Study.\u201d \nIn 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE. \nhttps://doi.org/10.1109/icde53745.2022.00077.\n</code></pre></p>"},{"location":"data/quantity_distributions/uniform/","title":"Uniform","text":"<p>This distribution type is a simple uniform distribution. This assumes an ideal scenario with an equal sample size for all clients. Each client is assigned a fixed percentage of the overall dataset. The total number of samples depends on the total number of clients. The samples are selected with replacement from the entire training set.</p>"},{"location":"data/quantity_distributions/uniform/#parameters","title":"Parameters","text":"Key Description Example Value data_quantity_base_parameter Percentage of data to assign to each client 0.01"},{"location":"examples/","title":"Example Descriptions","text":"<p>The examples folder contains a few examples for running SelecEval. The examples are provided as .json files and can be run using the following command: Runtime is provided as a rough estimate for a single run on a AMD Ryzen 9 3900X (24) @ 3.800GHz .  If you run into memory issues you can try to adjust the share of resources per simulated client in the .json file. Alternatively you may disable CUDA acceleration. <pre><code>python -m seleceval.run example_xxx.json\n</code></pre></p> <p>The examples are provided as follows:</p> Example Description Runtime example_1.json A simple example with 10 clients and 2 rounds of training on the MNIST dataset. Acceleration using CUDA is disabled. Only Random Selection and FedCS are included. &lt; 3 min example_2.json A simple example with 20 clients running all 5 algorithms on the MNIST dataset. &lt; 10 min"},{"location":"examples/example_1/","title":"Example 1","text":"<pre><code>{\n  \"no_rounds\": 2,\n  \"algorithm\": [\n    \"random\",\n    \"FedCS\"\n  ],\n  \"dataset\": \"mnist\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.2\n    },\n    \"FedCS\": {\n      \"c\": 0.2\n    }\n  },\n  \"data_config\" : {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Uniform\"\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 10,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cpu\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"output/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"seleceval/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cpu\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/example_2/","title":"Example 2","text":"<pre><code>{\n  \"no_rounds\": 2,\n  \"algorithm\": [\n    \"random\",\n    \"FedCS\",\n    \"PowD\",\n    \"CEP\",\n    \"ActiveFL\"\n  ],\n  \"dataset\": \"mnist\",\n  \"algorithm_config\": {\n    \"CEP\": {\n      \"c\": 0.2\n    },\n    \"PowD\": {\n      \"c\": 0.2\n    },\n    \"random\": {\n      \"c\": 0.2\n    },\n    \"ActiveFL\": {\n      \"c\": 0.2\n    },\n    \"FedCS\": {\n      \"c\": 0.2\n    }\n  },\n  \"data_config\" : {\n    \"data_quantity_skew\": \"Dirichlet\",\n    \"data_quantity_skew_parameter\": 4.0,\n    \"data_label_distribution_skew\": \"Uniform\"\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 20,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cpu\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"output/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"seleceval/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cpu\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/","title":"Thesis Configurations","text":"<p>This folder contains the configuration files used for the experiments in the thesis.</p>"},{"location":"examples/paper/IID/","title":"IID","text":"<pre><code>{\n  \"no_rounds\": 30,\n  \"algorithm\": [\n    \"random\",\n    \"ActiveFL\",\n    \"FedCS\",\n    \"PowD\",\n    \"CEP\"\n  ],\n  \"dataset\": \"cifar10\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.1\n    },\n    \"ActiveFL\": {\n      \"c\": 0.1\n    },\n    \"FedCS\": {\n      \"c\": 0.1,\n      \"fixed_client_no\": true\n    },\n    \"PowD\": {\n      \"c\": 0.1\n    },\n    \"CEP\": {\n      \"c\": 0.1\n    }\n  },\n  \"data_config\": {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Uniform\",\n    \"data_quantity_base_parameter\": 0.01\n  },\n  \"no_epochs\": 3,\n  \"no_clients\": 500,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/feature_skew/","title":"Feature skew","text":"<pre><code>{\n  \"no_rounds\": 10,\n  \"algorithm\": [\n    \"random\",\n    \"ActiveFL\",\n    \"FedCS\",\n    \"PowD\",\n    \"CEP\"\n  ],\n  \"dataset\": \"mnist\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.2\n    },\n    \"ActiveFL\": {\n      \"c\": 0.2\n    },\n    \"FedCS\": {\n      \"c\": 0.2\n    },\n    \"PowD\": {\n      \"c\": 0.2\n    },\n    \"CEP\": {\n      \"c\": 0.2\n    }\n  },\n  \"data_config\": {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Uniform\",\n    \"data_feature_skew\": \"Gaussian\"\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 50,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/flexible_client_count/","title":"Flexible client count","text":"<pre><code>{\n  \"no_rounds\": 10,\n  \"algorithm\": [\n    \"random\",\n    \"FedCS\",\n    \"CEP\"\n  ],\n  \"dataset\": \"cifar10\",\n  \"algorithm_config\": {\n        \"random\": {\n            \"c\": 0.1\n        },\n    \"ActiveFL\": {\n        \"c\": 0.1\n    },\n    \"FedCS\": {\n        \"c\": 0.1,\n        \"fixed_client_no\" : false\n    },\n    \"PowD\": {\n        \"c\": 0.1\n    },\n    \"CEP\": {\n        \"c\": 0.1\n    }\n  },\n  \"data_config\" : {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Dirichlet\",\n    \"data_label_distribution_parameter\": 4.0\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 100,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/label_quantity_skew/","title":"Label quantity skew","text":"<pre><code>{\n  \"no_rounds\": 30,\n  \"algorithm\": [\n    \"random\",\n    \"ActiveFL\",\n    \"FedCS\",\n    \"PowD\",\n    \"CEP\"\n  ],\n  \"dataset\": \"cifar10\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.1\n    },\n    \"ActiveFL\": {\n      \"c\": 0.1\n    },\n    \"FedCS\": {\n      \"c\": 0.1\n    },\n    \"PowD\": {\n      \"c\": 0.1\n    },\n    \"CEP\": {\n      \"c\": 0.1\n    }\n  },\n  \"data_config\": {\n    \"data_quantity_skew\": \"Dirichlet\",\n    \"data_label_distribution_skew\": \"Dirichlet\",\n    \"data_label_distribution_parameter\": 0.5\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 500,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/label_skew/","title":"Label skew","text":"<pre><code>{\n  \"no_rounds\": 30,\n  \"algorithm\": [\n    \"random\",\n    \"ActiveFL\",\n    \"FedCS\",\n    \"PowD\",\n    \"CEP\"\n  ],\n  \"dataset\": \"cifar10\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.1\n    },\n    \"ActiveFL\": {\n      \"c\": 0.1\n    },\n    \"FedCS\": {\n      \"c\": 0.1\n    },\n    \"PowD\": {\n      \"c\": 0.1\n    },\n    \"CEP\": {\n      \"c\": 0.1\n    }\n  },\n  \"data_config\": {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Dirichlet\",\n    \"data_label_distribution_parameter\": 0.5,\n    \"data_quantity_base_parameter\": 0.01\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 500,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"examples/paper/less_clients/","title":"Less clients","text":"<pre><code>{\n  \"no_rounds\": 10,\n  \"algorithm\": [\n    \"random\",\n    \"CEP\",\n    \"PowD\"\n  ],\n  \"dataset\": \"mnist\",\n  \"algorithm_config\": {\n    \"random\": {\n      \"c\": 0.1\n    },\n    \"PowD\": {\n      \"c\": 0.1\n    },\n    \"CEP\": {\n      \"c\": 0.1\n    }\n  },\n  \"data_config\": {\n    \"data_quantity_skew\": \"Uniform\",\n    \"data_label_distribution_skew\": \"Dirichlet\",\n    \"data_label_distribution_parameter\": 4.0\n  },\n  \"no_epochs\": 1,\n  \"no_clients\": 50,\n  \"batch_size\": 32,\n  \"verbose\": true,\n  \"device\": \"cuda\",\n  \"timeout\": 120,\n  \"generate_clients\": true,\n  \"output_dir\": \"outputs/o\",\n  \"client_state_file\": \"seleceval/client_states.csv\",\n  \"client_configuration_file\": \"seleceval/client_configurations.csv\",\n  \"distribute_data\": true,\n  \"data_distribution_file\": \"outputs/data_distribution.csv\",\n  \"validation_config\": {\n    \"enable_validation\": true,\n    \"enable_data_distribution\": true,\n    \"device\": \"cuda\"\n  },\n  \"max_workers\": 32\n}\n</code></pre>"},{"location":"module_docs/__main__/","title":"__main__","text":"<p>Main file for the simulation</p>"},{"location":"module_docs/__main__/#main","title":"main","text":"<pre><code>def main()\n</code></pre> <p>Main function for the simulation</p>"},{"location":"module_docs/__main__/#run_evaluation","title":"run_evaluation","text":"<pre><code>def run_evaluation(config, datahandler, trainloaders, valloaders)\n</code></pre> <p>Evaluates the performance of the algorithms</p> <p>Arguments:</p> <ul> <li><code>config</code>: Config object</li> <li><code>datahandler</code>: Datahandler object</li> <li><code>trainloaders</code>: List of trainloaders</li> <li><code>valloaders</code>: List of valloaders</li> </ul>"},{"location":"module_docs/__main__/#run_training_simulation","title":"run_training_simulation","text":"<pre><code>def run_training_simulation(DEVICE, NUM_CLIENTS, config, datahandler,\n                            trainloaders, valloaders)\n</code></pre> <p>Runs the training simulation</p> <p>Arguments:</p> <ul> <li><code>DEVICE</code>: Device to run the simulation on</li> <li><code>NUM_CLIENTS</code>: Number of clients</li> <li><code>config</code>: Config object</li> <li><code>datahandler</code>: Datahandler object</li> <li><code>trainloaders</code>: Trainloaders</li> <li><code>valloaders</code>: </li> </ul>"},{"location":"module_docs/client/","title":"Client","text":""},{"location":"module_docs/client/#table-of-contents","title":"Table of Contents","text":"<ul> <li>client.client_state</li> <li>ClientState<ul> <li>get</li> <li>get_all</li> </ul> </li> <li>client.client_output</li> <li>ClientOutput<ul> <li>set</li> <li>get</li> <li>write</li> </ul> </li> <li>client.client_fn</li> <li>ClientFunction<ul> <li>client_fn</li> </ul> </li> <li>client.client</li> <li>Client<ul> <li>fit</li> <li>evaluate</li> <li>get_properties</li> </ul> </li> <li>client.helpers</li> <li>get_parameters</li> <li>set_parameters</li> </ul>"},{"location":"module_docs/client/#client.client_state","title":"client.client_state","text":"<p>Client state class</p>"},{"location":"module_docs/client/#client.client_state.ClientState","title":"ClientState Objects","text":"<pre><code>class ClientState()\n</code></pre> <p>Utility class for handling client state</p>"},{"location":"module_docs/client/#client.client_state.ClientState.get","title":"get","text":"<pre><code>def get(attr) -&gt; Union[str, int, float]\n</code></pre> <p>Get attribute from state</p> <p>Arguments:</p> <ul> <li><code>attr</code>: Attribute to get</li> </ul> <p>Returns:</p> <p>Value of attribute</p>"},{"location":"module_docs/client/#client.client_state.ClientState.get_all","title":"get_all","text":"<pre><code>def get_all() -&gt; Dict\n</code></pre> <p>Get all attributes from state</p> <p>Returns:</p> <p>Dictionary of all attributes</p>"},{"location":"module_docs/client/#client.client_output","title":"client.client_output","text":"<p>Utility class for handling client output</p>"},{"location":"module_docs/client/#client.client_output.ClientOutput","title":"ClientOutput Objects","text":"<pre><code>class ClientOutput()\n</code></pre>"},{"location":"module_docs/client/#client.client_output.ClientOutput.set","title":"set","text":"<pre><code>def set(key: Union[str, int], value: Any)\n</code></pre> <p>Set output key to values</p> <p>Arguments:</p> <ul> <li><code>key</code>: String or integer key</li> <li><code>value</code>: Value to set</li> </ul>"},{"location":"module_docs/client/#client.client_output.ClientOutput.get","title":"get","text":"<pre><code>def get(key: Union[str, int]) -&gt; Any\n</code></pre> <p>Get output value for key</p> <p>Arguments:</p> <ul> <li><code>key</code>: String or integer key</li> </ul> <p>Returns:</p> <p>Value for key</p>"},{"location":"module_docs/client/#client.client_output.ClientOutput.write","title":"write","text":"<pre><code>def write()\n</code></pre> <p>Write output</p>"},{"location":"module_docs/client/#client.client_fn","title":"client.client_fn","text":"<p>Wrapper to allow Ray to create clients</p>"},{"location":"module_docs/client/#client.client_fn.ClientFunction","title":"ClientFunction Objects","text":"<pre><code>class ClientFunction()\n</code></pre> <p>Class used to create clients</p>"},{"location":"module_docs/client/#client.client_fn.ClientFunction.client_fn","title":"client_fn","text":"<pre><code>def client_fn(cid: str) -&gt; Client\n</code></pre> <p>Function used to create clients</p> <p>Arguments:</p> <ul> <li><code>cid</code>: The client id</li> </ul> <p>Returns:</p> <p>Instance of the client class</p>"},{"location":"module_docs/client/#client.client","title":"client.client","text":"<p>Client class for the federated learning framework</p>"},{"location":"module_docs/client/#client.client.Client","title":"Client Objects","text":"<pre><code>class Client(fl.client.NumPyClient)\n</code></pre>"},{"location":"module_docs/client/#client.client.Client.fit","title":"fit","text":"<pre><code>def fit(parameters: List[ndarray],\n        config: flwr.common.FitIns) -&gt; Tuple[List[ndarray], int, Dict]\n</code></pre> <p>Fit the model, write output and return parameters and metrics</p> <p>Arguments:</p> <ul> <li><code>parameters</code>: The current parameters of the global model</li> <li><code>config</code>: Configuration for this fit</li> </ul> <p>Returns:</p> <p>The parameters of the global model, the number of samples used and the metrics</p>"},{"location":"module_docs/client/#client.client.Client.evaluate","title":"evaluate","text":"<pre><code>def evaluate(parameters, config)\n</code></pre> <p>Evaluate the model</p> <p>Arguments:</p> <ul> <li><code>parameters</code>: model parameters</li> <li><code>config</code>: configuration for this evaluation</li> </ul> <p>Returns:</p> <p>loss, number of samples and metrics</p>"},{"location":"module_docs/client/#client.client.Client.get_properties","title":"get_properties","text":"<pre><code>def get_properties(config=None) -&gt; Dict\n</code></pre> <p>Return properties of the current client</p> <p>Arguments:</p> <ul> <li><code>config</code>: Config for getting the properties</li> </ul>"},{"location":"module_docs/client/#client.helpers","title":"client.helpers","text":"<p>Helper functions for the client Specifically, this file contains the following functions:     - get_parameters: Returns the parameters of a model as a list of numpy arrays     - set_parameters: Sets the parameters of a model from a list of numpy arrays</p>"},{"location":"module_docs/client/#client.helpers.get_parameters","title":"get_parameters","text":"<pre><code>def get_parameters(net) -&gt; List[np.ndarray]\n</code></pre> <p>Returns the parameters of a model as a list of numpy arrays</p> <p>Arguments:</p> <ul> <li><code>net</code>: The model</li> </ul> <p>Returns:</p> <p>The parameters of the model as a list of numpy arrays</p>"},{"location":"module_docs/client/#client.helpers.set_parameters","title":"set_parameters","text":"<pre><code>def set_parameters(net, parameters: List[np.ndarray])\n</code></pre> <p>Sets the parameters of a model from a list of numpy arrays</p> <p>Arguments:</p> <ul> <li><code>net</code>: The model</li> <li><code>parameters</code>: The parameters of the model as a list of numpy arrays</li> </ul> <p>Returns:</p> <p>None</p>"},{"location":"module_docs/datahandler/","title":"DataHandler","text":""},{"location":"module_docs/datahandler/#table-of-contents","title":"Table of Contents","text":"<ul> <li>datahandler.data_feature_distribution.gaussian</li> <li>GaussianNoiseTransform</li> <li>datahandler.data_feature_distribution</li> <li>datahandler.data_feature_distribution.data_feature_distribution</li> <li>DataFeatureDistribution<ul> <li>apply_feature_skew</li> </ul> </li> <li>datahandler.datahandler</li> <li>DataHandler<ul> <li>load_distributed_datasets</li> <li>get_classes</li> <li>split_and_transform_data</li> <li>distribute_data</li> <li>load_existing_distribution</li> <li>generate_transforms</li> </ul> </li> <li>datahandler.data_label_distribution.uniform</li> <li>Uniform<ul> <li>get_label_distribution</li> </ul> </li> <li>datahandler.data_label_distribution.data_label_distribution</li> <li>DataLabelDistribution<ul> <li>get_label_distribution</li> </ul> </li> <li>datahandler.data_label_distribution</li> <li>datahandler.data_label_distribution.discrete</li> <li>Discrete<ul> <li>get_label_distribution</li> </ul> </li> <li>datahandler.data_label_distribution.dirichlet</li> <li>Dirichlet<ul> <li>get_label_distribution</li> </ul> </li> <li>datahandler.mnist</li> <li>MNISTDataHandler<ul> <li>load_distributed_datasets</li> <li>get_classes</li> </ul> </li> <li>datahandler.cifar10</li> <li>Cifar10DataHandler<ul> <li>load_distributed_datasets</li> <li>get_classes</li> </ul> </li> <li>datahandler.data_quantity_distribution.uniform</li> <li>Uniform<ul> <li>get_partition_sizes</li> </ul> </li> <li>datahandler.data_quantity_distribution.data_quantity_distribution</li> <li>DataQuantityDistribution<ul> <li>get_partition_sizes</li> </ul> </li> <li>datahandler.data_quantity_distribution</li> <li>datahandler.data_quantity_distribution.dirichlet</li> <li>Dirichlet<ul> <li>get_partition_sizes</li> </ul> </li> </ul>"},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution.gaussian","title":"datahandler.data_feature_distribution.gaussian","text":""},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution.gaussian.GaussianNoiseTransform","title":"GaussianNoiseTransform Objects","text":"<pre><code>class GaussianNoiseTransform(object)\n</code></pre> <p>Add Gaussian noise to a tensor</p>"},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution","title":"datahandler.data_feature_distribution","text":"<p>This module contains methods of skewing data features</p>"},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution.data_feature_distribution","title":"datahandler.data_feature_distribution.data_feature_distribution","text":"<p>DataFeatureDistribution is an abstract class that defines the interface for any implemented data feature distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution.data_feature_distribution.DataFeatureDistribution","title":"DataFeatureDistribution Objects","text":"<pre><code>class DataFeatureDistribution(ABC)\n</code></pre> <p>DataFeatureDistribution is an abstract class that defines the interface for any implemented data feature distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_feature_distribution.data_feature_distribution.DataFeatureDistribution.apply_feature_skew","title":"apply_feature_skew","text":"<pre><code>def apply_feature_skew(datahandler)\n</code></pre> <p>Applies the feature skew to the data</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler","title":"datahandler.datahandler","text":"<p>This contains the abstract data handler that defines the interface for any implemented data handlers and provides some universal methods</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler","title":"DataHandler Objects","text":"<pre><code>class DataHandler(ABC)\n</code></pre> <p>DataHandler is an abstract class that defines the interface for any implemented data handlers</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.load_distributed_datasets","title":"load_distributed_datasets","text":"<pre><code>@abstractmethod\ndef load_distributed_datasets()\n</code></pre> <p>Called to load the dataset</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.get_classes","title":"get_classes","text":"<pre><code>@abstractmethod\ndef get_classes()\n</code></pre> <p>Returns the classes of the dataset</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.split_and_transform_data","title":"split_and_transform_data","text":"<pre><code>def split_and_transform_data(testset, trainset)\n</code></pre> <p>Split the data into partitions and create DataLoaders</p> <p>Arguments:</p> <ul> <li><code>testset</code>: test dataset</li> <li><code>trainset</code>: training dataset</li> </ul> <p>Returns:</p> <p>testloader, trainloaders, valloaders</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.distribute_data","title":"distribute_data","text":"<pre><code>def distribute_data(label_distribution, partition_sizes, trainset)\n</code></pre> <p>Distribute the data according to the label distribution and partition sizes</p> <p>Arguments:</p> <ul> <li><code>label_distribution</code>: np.array of shape (NUM_CLIENTS, NUM_CLASSES)</li> <li><code>partition_sizes</code>: np.array of shape (NUM_CLIENTS)</li> <li><code>trainset</code>: torch.utils.data.Dataset</li> </ul> <p>Returns:</p> <p>list of torch.utils.data.Subset</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.load_existing_distribution","title":"load_existing_distribution","text":"<pre><code>def load_existing_distribution(trainset)\n</code></pre> <p>Load an existing data distribution from a file</p> <p>Arguments:</p> <ul> <li><code>trainset</code>: torch.utils.data.Dataset</li> </ul> <p>Returns:</p> <p>List of torch.utils.data.Subset</p>"},{"location":"module_docs/datahandler/#datahandler.datahandler.DataHandler.generate_transforms","title":"generate_transforms","text":"<pre><code>def generate_transforms(custom_transforms=None)\n</code></pre> <p>Generate the transforms for the dataset</p> <p>Custom transforms are applied after a tensor was created and before normalization and feature skewing</p> <p>Arguments:</p> <ul> <li><code>custom_transforms</code>: List of custom transforms</li> </ul> <p>Returns:</p> <p>Composed transforms</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.uniform","title":"datahandler.data_label_distribution.uniform","text":"<p>Uniform distribution of labels</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.uniform.Uniform","title":"Uniform Objects","text":"<pre><code>class Uniform(DataLabelDistribution)\n</code></pre> <p>Uniform distribution of labels</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.uniform.Uniform.get_label_distribution","title":"get_label_distribution","text":"<pre><code>def get_label_distribution()\n</code></pre> <p>Returns the label distribution as an array of dimension (no_clients, no_classes)</p> <p>Uses uniform distribution to (not-)skew the data label distribution</p> <p>Returns:</p> <p>label_distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.data_label_distribution","title":"datahandler.data_label_distribution.data_label_distribution","text":"<p>DataLabelDistribution is an abstract class that defines the interface for any implemented data label distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.data_label_distribution.DataLabelDistribution","title":"DataLabelDistribution Objects","text":"<pre><code>class DataLabelDistribution(ABC)\n</code></pre> <p>DataLabelDistribution is an abstract class that defines the interface for any implemented data label distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.data_label_distribution.DataLabelDistribution.get_label_distribution","title":"get_label_distribution","text":"<pre><code>def get_label_distribution()\n</code></pre> <p>Returns the label distribution as an array of dimension (no_clients, no_classes)</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution","title":"datahandler.data_label_distribution","text":"<p>This module contains methods of skewing data labels</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.discrete","title":"datahandler.data_label_distribution.discrete","text":"<p>Discrete data label distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.discrete.Discrete","title":"Discrete Objects","text":"<pre><code>class Discrete(DataLabelDistribution)\n</code></pre> <p>Discrete data label distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.discrete.Discrete.get_label_distribution","title":"get_label_distribution","text":"<pre><code>def get_label_distribution()\n</code></pre> <p>Returns the label distribution as an array of dimension no_clients, no_classes</p> <p>Allows each client to have only a subset of the classes</p> <p>Returns:</p> <p>label_distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.dirichlet","title":"datahandler.data_label_distribution.dirichlet","text":"<p>Dirichlet distribution for data label distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.dirichlet.Dirichlet","title":"Dirichlet Objects","text":"<pre><code>class Dirichlet(DataLabelDistribution)\n</code></pre> <p>Dirichlet distribution for data label distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_label_distribution.dirichlet.Dirichlet.get_label_distribution","title":"get_label_distribution","text":"<pre><code>def get_label_distribution()\n</code></pre> <p>Returns the label distribution as an array of dimension (no_clients, no_classes)</p> <p>Uses a dirichlet distribution to skew the data label distribution</p> <p>Returns:</p> <p>label_distribution</p>"},{"location":"module_docs/datahandler/#datahandler.mnist","title":"datahandler.mnist","text":"<p>MNIST data handler LeCun, Yann, Corinna Cortes, and C. J. Burges. n.d. \u201cMNIST Handwritten Digit Database.\u201d ATT Labs [Online]. Available: Http://yann. Lecun. Com/exdb/mnist.</p>"},{"location":"module_docs/datahandler/#datahandler.mnist.MNISTDataHandler","title":"MNISTDataHandler Objects","text":"<pre><code>class MNISTDataHandler(DataHandler)\n</code></pre>"},{"location":"module_docs/datahandler/#datahandler.mnist.MNISTDataHandler.load_distributed_datasets","title":"load_distributed_datasets","text":"<pre><code>def load_distributed_datasets()\n</code></pre> <p>Load the MNIST dataset and divide it into partitions</p>"},{"location":"module_docs/datahandler/#datahandler.mnist.MNISTDataHandler.get_classes","title":"get_classes","text":"<pre><code>def get_classes()\n</code></pre> <p>Returns the classes of the dataset</p> <p>Returns:</p> <p>List of classes</p>"},{"location":"module_docs/datahandler/#datahandler.cifar10","title":"datahandler.cifar10","text":"<p>CIFAR-10 data handler He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. \u201cDeep Residual Learning for Image Recognition.\u201d arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1512.03385.</p>"},{"location":"module_docs/datahandler/#datahandler.cifar10.Cifar10DataHandler","title":"Cifar10DataHandler Objects","text":"<pre><code>class Cifar10DataHandler(DataHandler)\n</code></pre> <p>Data handler for CIFAR-10</p>"},{"location":"module_docs/datahandler/#datahandler.cifar10.Cifar10DataHandler.load_distributed_datasets","title":"load_distributed_datasets","text":"<pre><code>def load_distributed_datasets()\n</code></pre> <p>Load the CIFAR-10 dataset and divide it into partitions</p> <p>Returns:</p> <p>Train, validation and test data loaders</p>"},{"location":"module_docs/datahandler/#datahandler.cifar10.Cifar10DataHandler.get_classes","title":"get_classes","text":"<pre><code>def get_classes()\n</code></pre> <p>Get the classes of the CIFAR-10 dataset</p> <p>Returns:</p> <p>List of classes</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.uniform","title":"datahandler.data_quantity_distribution.uniform","text":"<p>Uniform data quantity distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.uniform.Uniform","title":"Uniform Objects","text":"<pre><code>class Uniform(DataQuantityDistribution)\n</code></pre> <p>Uniform data quantity distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.uniform.Uniform.get_partition_sizes","title":"get_partition_sizes","text":"<pre><code>def get_partition_sizes(testset, trainset)\n</code></pre> <p>Returns the partition sizes as an array of dimension (no_clients)</p> <p>Uses a uniform distribution to (not-)skew the data quantities</p> <p>Arguments:</p> <ul> <li><code>testset</code>: test dataset</li> <li><code>trainset</code>: train dataset</li> </ul>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.data_quantity_distribution","title":"datahandler.data_quantity_distribution.data_quantity_distribution","text":"<p>This class contains the abstract class DataQuantityDistribution which is used to for all implemented data quantity distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.data_quantity_distribution.DataQuantityDistribution","title":"DataQuantityDistribution Objects","text":"<pre><code>class DataQuantityDistribution(ABC)\n</code></pre> <p>DataQuantityDistribution is an abstract class that defines the interface for any implemented data quantity distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.data_quantity_distribution.DataQuantityDistribution.get_partition_sizes","title":"get_partition_sizes","text":"<pre><code>def get_partition_sizes(testset, trainset)\n</code></pre> <p>Returns the number of samples to be allocated to every client</p> <p>Arguments:</p> <ul> <li><code>testset</code>: test dataset</li> <li><code>trainset</code>: training dataset</li> </ul>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution","title":"datahandler.data_quantity_distribution","text":"<p>This module contains the classes for skewing data quantity distributions</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.dirichlet","title":"datahandler.data_quantity_distribution.dirichlet","text":"<p>Dirichlet distribution for data quantity distribution</p>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.dirichlet.Dirichlet","title":"Dirichlet Objects","text":"<pre><code>class Dirichlet(DataQuantityDistribution)\n</code></pre>"},{"location":"module_docs/datahandler/#datahandler.data_quantity_distribution.dirichlet.Dirichlet.get_partition_sizes","title":"get_partition_sizes","text":"<pre><code>def get_partition_sizes(testset, trainset)\n</code></pre> <p>Returns the number of samples to be allocated to every client</p> <p>Arguments:</p> <ul> <li><code>testset</code>: test dataset</li> <li><code>trainset</code>: training dataset</li> </ul> <p>Returns:</p> <p>Array of size (no_clients) containing the number of samples for every client</p>"},{"location":"module_docs/models/","title":"Models","text":""},{"location":"module_docs/models/#table-of-contents","title":"Table of Contents","text":"<ul> <li>models.model</li> <li>Model<ul> <li>train</li> <li>test</li> <li>get_net</li> <li>get_size</li> </ul> </li> <li>models.resnet18</li> <li>Resnet18<ul> <li>get_net</li> <li>get_size</li> <li>train</li> <li>test</li> </ul> </li> </ul>"},{"location":"module_docs/models/#models.model","title":"models.model","text":"<p>Abstract class for models</p>"},{"location":"module_docs/models/#models.model.Model","title":"Model Objects","text":"<pre><code>class Model(ABC)\n</code></pre>"},{"location":"module_docs/models/#models.model.Model.train","title":"train","text":"<pre><code>@abstractmethod\ndef train(trainloader: DataLoader,\n          client_name: str,\n          epochs: int,\n          verbose: bool = False) -&gt; Dict\n</code></pre> <p>Method for running a training round</p> <p>Arguments:</p> <ul> <li><code>trainloader</code>: Data loader for training data</li> <li><code>client_name</code>: Name of the current client</li> <li><code>epochs</code>: Number of epochs to train</li> <li><code>verbose</code>: Whether to print verbose output</li> </ul>"},{"location":"module_docs/models/#models.model.Model.test","title":"test","text":"<pre><code>@abstractmethod\ndef test(testloader: DataLoader,\n         client_name: str,\n         verbose: bool = False) -&gt; Tuple[float, float, dict]\n</code></pre> <p>Method for running a test round</p> <p>Arguments:</p> <ul> <li><code>testloader</code>: Data loader for test data</li> <li><code>client_name</code>: Name of the current client</li> <li><code>verbose</code>: Whether to print verbose output</li> </ul>"},{"location":"module_docs/models/#models.model.Model.get_net","title":"get_net","text":"<pre><code>@abstractmethod\ndef get_net()\n</code></pre> <p>Returns the current deep network</p>"},{"location":"module_docs/models/#models.model.Model.get_size","title":"get_size","text":"<pre><code>@abstractmethod\ndef get_size()\n</code></pre> <p>Returns the size of the current deep network</p>"},{"location":"module_docs/models/#models.resnet18","title":"models.resnet18","text":"<p>Resnet18 model for federated learning</p>"},{"location":"module_docs/models/#models.resnet18.Resnet18","title":"Resnet18 Objects","text":"<pre><code>class Resnet18(Model)\n</code></pre> <p>Resnet18 model for federated learning</p>"},{"location":"module_docs/models/#models.resnet18.Resnet18.get_net","title":"get_net","text":"<pre><code>def get_net() -&gt; nn.Module\n</code></pre> <p>Returns the current deep network</p> <p>Returns:</p> <p>The current deep network</p>"},{"location":"module_docs/models/#models.resnet18.Resnet18.get_size","title":"get_size","text":"<pre><code>def get_size() -&gt; float\n</code></pre> <p>Returns the size of the current deep network</p> <p>Returns:</p> <p>The size of the current deep network</p>"},{"location":"module_docs/models/#models.resnet18.Resnet18.train","title":"train","text":"<pre><code>def train(trainloader: DataLoader,\n          client_name: str,\n          epochs: int,\n          verbose: bool = False) -&gt; Dict\n</code></pre> <p>Method for running a training round using cross entropy loss</p> <p>Arguments:</p> <ul> <li><code>trainloader</code>: Data loader for training data</li> <li><code>client_name</code>: Name of the current client</li> <li><code>epochs</code>: Number of epochs to train</li> <li><code>verbose</code>: Whether to print verbose output</li> </ul> <p>Returns:</p> <p>Metrics of the training round</p>"},{"location":"module_docs/models/#models.resnet18.Resnet18.test","title":"test","text":"<pre><code>def test(testloader: DataLoader,\n         client_name: str,\n         verbose: bool = False) -&gt; Tuple[float, float, dict]\n</code></pre> <p>Method for running a test round</p> <p>Arguments:</p> <ul> <li><code>testloader</code>: Data loader for test data</li> <li><code>client_name</code>: Name of the current client</li> <li><code>verbose</code>: Whether to print verbose output</li> </ul> <p>Returns:</p> <p>Metrics of the test round</p>"},{"location":"module_docs/selection/","title":"Selection","text":""},{"location":"module_docs/selection/#table-of-contents","title":"Table of Contents","text":"<ul> <li>selection.min_cpu</li> <li>MinCPU<ul> <li>select_clients</li> </ul> </li> <li>selection.active</li> <li>ActiveFL<ul> <li>select_clients</li> <li>calculate_valuation</li> </ul> </li> <li>selection.client_selection</li> <li>ClientSelection<ul> <li>select_clients</li> <li>run_task_get_properties</li> <li>run_task_evaluate</li> </ul> </li> <li>selection.powd</li> <li>PowD<ul> <li>select_clients</li> </ul> </li> <li>selection.fedcs</li> <li>FedCS<ul> <li>select_clients</li> </ul> </li> <li>selection.cep</li> <li>unique</li> <li>CEP<ul> <li>select_clients</li> <li>calculate_ces</li> </ul> </li> <li>selection.random_selection</li> <li>RandomSelection<ul> <li>select_clients</li> </ul> </li> <li>selection.helpers</li> <li>get_client_properties</li> </ul>"},{"location":"module_docs/selection/#selection.min_cpu","title":"selection.min_cpu","text":"<p>Example of a custom client selection algorithm Not available for testing - can be used as a template for implementing new algorithms</p>"},{"location":"module_docs/selection/#selection.min_cpu.MinCPU","title":"MinCPU Objects","text":"<pre><code>class MinCPU(ClientSelection)\n</code></pre>"},{"location":"module_docs/selection/#selection.min_cpu.MinCPU.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on the MinCPU algorithm</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.active","title":"selection.active","text":"<p>ActiveFL Client Selection Algorithm Based on Goetz, Jack, Kshitiz Malik, D. Bui, Seungwhan Moon, Honglei Liu, and Anuj Kumar. 2019. \u201cActive Federated Learning.\u201d arXiv.org. https://www.semanticscholar.org/paper/36b9b82b607149f160abde58db77149c6de58c01.</p>"},{"location":"module_docs/selection/#selection.active.ActiveFL","title":"ActiveFL Objects","text":"<pre><code>class ActiveFL(ClientSelection)\n</code></pre> <p>ActiveFL Client Selection Algorithm</p>"},{"location":"module_docs/selection/#selection.active.ActiveFL.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on the CEP algorithm</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.active.ActiveFL.calculate_valuation","title":"calculate_valuation","text":"<pre><code>def calculate_valuation(server_round)\n</code></pre> <p>Calculate the valuation of each client</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: The current server round</li> </ul>"},{"location":"module_docs/selection/#selection.client_selection","title":"selection.client_selection","text":"<p>Abstract class for client selection algorithms</p>"},{"location":"module_docs/selection/#selection.client_selection.ClientSelection","title":"ClientSelection Objects","text":"<pre><code>class ClientSelection(ABC)\n</code></pre> <p>Abstract class for client selection algorithms</p>"},{"location":"module_docs/selection/#selection.client_selection.ClientSelection.select_clients","title":"select_clients","text":"<pre><code>@abstractmethod\ndef select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters, server_round: int)\n</code></pre> <p>Core function used to select client utilizing the existing client manager and the current parameters.</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.client_selection.ClientSelection.run_task_get_properties","title":"run_task_get_properties","text":"<pre><code>def run_task_get_properties(\n    clients: List[ClientProxy]\n) -&gt; Tuple[List[Tuple[ClientProxy, GetPropertiesRes]], List[Union[Tuple[\n        ClientProxy, GetPropertiesRes], BaseException]], ]\n</code></pre> <p>Run the get properties task on the given clients</p> <p>Arguments:</p> <ul> <li><code>clients</code>: List of clients</li> </ul> <p>Returns:</p> <p>successful and failed executions</p>"},{"location":"module_docs/selection/#selection.client_selection.ClientSelection.run_task_evaluate","title":"run_task_evaluate","text":"<pre><code>def run_task_evaluate(\n    clients: List[ClientProxy], parameters: Parameters\n) -&gt; Tuple[List[Tuple[ClientProxy, EvaluateRes]], List[Union[Tuple[\n        ClientProxy, EvaluateRes], BaseException]], ]\n</code></pre> <p>Run the evaluate task on the given clients</p> <p>Arguments:</p> <ul> <li><code>clients</code>: List of clients</li> <li><code>parameters</code>: Current global network parameters</li> </ul> <p>Returns:</p> <p>successful and failed executions</p>"},{"location":"module_docs/selection/#selection.powd","title":"selection.powd","text":"<p>Client selection algorithm based on the Pow-D algorithm Power of Choice Cho, Yae Jee, Jianyu Wang, and Gauri Joshi. 2020. \u201cClient Selection in Federated Learning: Convergence Analysis and Power-of-Choice Selection Strategies.\u201d arXiv.org. https://www.semanticscholar.org/paper/e245f15bdddac514454fecf32f2a3ecb069f6dec.</p>"},{"location":"module_docs/selection/#selection.powd.PowD","title":"PowD Objects","text":"<pre><code>class PowD(ClientSelection)\n</code></pre> <p>Pow-D algorithm for client selection</p>"},{"location":"module_docs/selection/#selection.powd.PowD.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on the Pow-D algorithm</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.fedcs","title":"selection.fedcs","text":"<p>This file implements the FedCS algorithm for client selection Nishio, Takayuki, and Ryo Yonetani. 2018. \u201cClient Selection for Federated Learning with Heterogeneous Resources in Mobile Edge.\u201d arXiv [cs.NI]. arXiv. http://arxiv.org/abs/1804.08333.</p>"},{"location":"module_docs/selection/#selection.fedcs.FedCS","title":"FedCS Objects","text":"<pre><code>class FedCS(ClientSelection)\n</code></pre> <p>FedCS algorithm for client selection</p>"},{"location":"module_docs/selection/#selection.fedcs.FedCS.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on the FedCS algorithm</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.cep","title":"selection.cep","text":"<p>Client Eligibility Protocol (CEP) algorithm for client selection in federated learning Asad, Muhammad, Safa Otoum, and Saima Shaukat. 2022. \u201cResource and Heterogeneity-Aware Clients Eligibility Protocol in Federated Learning.\u201d In GLOBECOM 2022 - 2022 IEEE Global Communications Conference, 1140\u201345.</p>"},{"location":"module_docs/selection/#selection.cep.unique","title":"unique","text":"<pre><code>def unique(s)\n</code></pre> <p>Check if all elements in a list are unique</p> <p>Arguments:</p> <ul> <li><code>s</code>: List</li> </ul> <p>Returns:</p> <p>True if all elements are unique, False otherwise</p>"},{"location":"module_docs/selection/#selection.cep.CEP","title":"CEP Objects","text":"<pre><code>class CEP(ClientSelection)\n</code></pre> <p>Client Eligibility Protocol (CEP) algorithm for client selection in federated learning</p>"},{"location":"module_docs/selection/#selection.cep.CEP.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on the CEP algorithm</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected clients</p>"},{"location":"module_docs/selection/#selection.cep.CEP.calculate_ces","title":"calculate_ces","text":"<pre><code>def calculate_ces(possible_clients, server_round)\n</code></pre> <p>Calculate the Client Eligibility Score (CES) for each client</p> <p>Arguments:</p> <ul> <li><code>possible_clients</code>: List of possible clients</li> <li><code>server_round</code>: The current server round</li> </ul>"},{"location":"module_docs/selection/#selection.random_selection","title":"selection.random_selection","text":"<p>Random Selection algorithm Provided as a baseline for comparison McMahan, H. Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag\u00fcera y. Arcas. 2016. \u201cCommunication-Efficient Learning of Deep Networks from Decentralized Data.\u201d arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1602.05629.</p>"},{"location":"module_docs/selection/#selection.random_selection.RandomSelection","title":"RandomSelection Objects","text":"<pre><code>class RandomSelection(ClientSelection)\n</code></pre> <p>Random Selection algorithm</p>"},{"location":"module_docs/selection/#selection.random_selection.RandomSelection.select_clients","title":"select_clients","text":"<pre><code>def select_clients(client_manager: fl.server.ClientManager,\n                   parameters: fl.common.Parameters,\n                   server_round: int) -&gt; List[Tuple[ClientProxy, FitIns]]\n</code></pre> <p>Select clients based on random selection</p> <p>Arguments:</p> <ul> <li><code>client_manager</code>: The client manager</li> <li><code>parameters</code>: The current parameters</li> <li><code>server_round</code>: The current server round</li> </ul> <p>Returns:</p> <p>Selected Clients</p>"},{"location":"module_docs/selection/#selection.helpers","title":"selection.helpers","text":"<p>Helper functions for selection algorithms</p>"},{"location":"module_docs/selection/#selection.helpers.get_client_properties","title":"get_client_properties","text":"<pre><code>def get_client_properties(client: ClientProxy, property_ins: GetPropertiesIns,\n                          timeout: int)\n</code></pre> <p>Get the properties of a client</p> <p>Arguments:</p> <ul> <li><code>client</code>: The client proxy (for ray)</li> <li><code>property_ins</code>: Config for getting properties (not used)</li> <li><code>timeout</code>: Timeout for getting properties</li> </ul> <p>Returns:</p> <p>The client proxy and the properties</p>"},{"location":"module_docs/strategy/","title":"Strategy","text":""},{"location":"module_docs/strategy/#table-of-contents","title":"Table of Contents","text":"<ul> <li>strategy.adjusted_fed_med</li> <li>AdjustedFedMedian<ul> <li>configure_fit</li> <li>aggregate_fit</li> </ul> </li> <li>strategy.adjusted_fed_avg</li> <li>AdjustedFedAvg<ul> <li>configure_fit</li> <li>aggregate_fit</li> </ul> </li> <li>strategy.common</li> <li>weighted_average</li> <li>strategy.adjusted_fed_avg_m</li> <li>AdjustedFedAvgM<ul> <li>configure_fit</li> <li>aggregate_fit</li> </ul> </li> </ul>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_med","title":"strategy.adjusted_fed_med","text":"<p>Adjusted FedMedian strategy Based on the FedMedian strategy from Flower Yin, Dong, Yudong Chen, Kannan Ramchandran, and Peter Bartlett. 2018. \u201cByzantine-Robust Distributed Learning: Towards Optimal Statistical Rates.\u201d arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1803.01498.</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_med.AdjustedFedMedian","title":"AdjustedFedMedian Objects","text":"<pre><code>class AdjustedFedMedian(fl.server.strategy.FedMedian)\n</code></pre>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_med.AdjustedFedMedian.configure_fit","title":"configure_fit","text":"<pre><code>def configure_fit(server_round: int, parameters: Parameters,\n                  client_manager: ClientManager)\n</code></pre> <p>Configure the fit process and select clients</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: The current server round</li> <li><code>parameters</code>: The current model parameters</li> <li><code>client_manager</code>: The client manager</li> </ul> <p>Returns:</p> <p>List of clients to train on</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_med.AdjustedFedMedian.aggregate_fit","title":"aggregate_fit","text":"<pre><code>def aggregate_fit(\n    server_round: int, results: List[Tuple[ClientProxy, fl.common.FitRes]],\n    failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]\n) -&gt; Tuple[Optional[Parameters], Dict[str, Scalar]]\n</code></pre> <p>Aggregate model weights using weighted average and store checkpoint, update state, set current round</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: The current server round</li> <li><code>results</code>: The results from the clients</li> <li><code>failures</code>: The failures from the clients</li> </ul> <p>Returns:</p> <p>The aggregated parameters and metrics</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg","title":"strategy.adjusted_fed_avg","text":"<p>Adjusted FedAvg strategy Based on the FedAvg strategy from Flower McMahan, H. Brendan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Ag\u00fcera y. Arcas. 2016. \u201cCommunication-Efficient Learning of Deep Networks from Decentralized Data.\u201d arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1602.05629.</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg.AdjustedFedAvg","title":"AdjustedFedAvg Objects","text":"<pre><code>class AdjustedFedAvg(fl.server.strategy.FedAvg)\n</code></pre>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg.AdjustedFedAvg.configure_fit","title":"configure_fit","text":"<pre><code>def configure_fit(server_round: int, parameters: Parameters,\n                  client_manager: ClientManager)\n</code></pre> <p>Configure the fit process</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: Current server round</li> <li><code>parameters</code>: Current model parameters</li> <li><code>client_manager</code>: Client manager</li> </ul> <p>Returns:</p> <p>List of clients to train</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg.AdjustedFedAvg.aggregate_fit","title":"aggregate_fit","text":"<pre><code>def aggregate_fit(\n    server_round: int, results: List[Tuple[ClientProxy, fl.common.FitRes]],\n    failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]\n) -&gt; Tuple[Optional[Parameters], Dict[str, Scalar]]\n</code></pre> <p>Aggregate model weights using weighted average and store checkpoint, update state, set current round</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: Current server round</li> <li><code>results</code>: List of results from clients</li> <li><code>failures</code>: List of failures from clients</li> </ul> <p>Returns:</p> <p>Aggregated parameters and metrics</p>"},{"location":"module_docs/strategy/#strategy.common","title":"strategy.common","text":"<p>Common functions for strategies</p>"},{"location":"module_docs/strategy/#strategy.common.weighted_average","title":"weighted_average","text":"<pre><code>def weighted_average(metrics: List[Tuple[int, Metrics]]) -&gt; Metrics\n</code></pre> <p>Calculate weighted average of accuracy</p> <p>Arguments:</p> <ul> <li><code>metrics</code>: Metrics including accuracy and number of examples</li> </ul> <p>Returns:</p> <p>weighted metrics</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg_m","title":"strategy.adjusted_fed_avg_m","text":"<p>Adjusted FedAvgM strategy Based on the FedAvgM strategy from Flower Hsu, Tzu-Ming Harry, Hang Qi, and Matthew Brown. 2019. \u201cMeasuring the Effects of Non-Identical Data Distribution for Federated Visual Classification.\u201d arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1909.06335.</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg_m.AdjustedFedAvgM","title":"AdjustedFedAvgM Objects","text":"<pre><code>class AdjustedFedAvgM(fl.server.strategy.FedAvgM)\n</code></pre>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg_m.AdjustedFedAvgM.configure_fit","title":"configure_fit","text":"<pre><code>def configure_fit(server_round: int, parameters: Parameters,\n                  client_manager: ClientManager)\n</code></pre> <p>Configure the fit process</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: The current server round</li> <li><code>parameters</code>: The current model parameters</li> <li><code>client_manager</code>: The client manager</li> </ul> <p>Returns:</p> <p>List of clients to train on</p>"},{"location":"module_docs/strategy/#strategy.adjusted_fed_avg_m.AdjustedFedAvgM.aggregate_fit","title":"aggregate_fit","text":"<pre><code>def aggregate_fit(\n    server_round: int, results: List[Tuple[ClientProxy, fl.common.FitRes]],\n    failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]]\n) -&gt; Tuple[Optional[Parameters], Dict[str, Scalar]]\n</code></pre> <p>Aggregate model weights using weighted average and store checkpoint, update state, set current round</p> <p>Arguments:</p> <ul> <li><code>server_round</code>: The current server round</li> <li><code>results</code>: The results from the clients</li> <li><code>failures</code>: The failures from the clients</li> </ul> <p>Returns:</p> <p>The aggregated parameters and metrics</p>"},{"location":"module_docs/util/","title":"Utility","text":""},{"location":"module_docs/util/#table-of-contents","title":"Table of Contents","text":"<ul> <li>util.arguments</li> <li>Arguments<ul> <li>get_args</li> </ul> </li> <li>util.config_parameters.base_strategy_parameters</li> <li>util.config_parameters.quantity_distribution_parameters</li> <li>util.config_parameters.feature_distribution_parameters</li> <li>util.config_parameters.algorithm_parameters</li> <li>util.config_parameters.label_distribution_parameters</li> <li>util.config_parameters</li> <li>util.config</li> <li>Config<ul> <li>set_current_round</li> <li>get_current_round</li> <li>generate_paths</li> </ul> </li> </ul>"},{"location":"module_docs/util/#util.arguments","title":"util.arguments","text":"<p>Argument parser for the simulation</p>"},{"location":"module_docs/util/#util.arguments.Arguments","title":"Arguments Objects","text":"<pre><code>class Arguments()\n</code></pre> <p>Argument parser for the simulation</p>"},{"location":"module_docs/util/#util.arguments.Arguments.get_args","title":"get_args","text":"<pre><code>def get_args()\n</code></pre> <p>Get the arguments from the parser</p> <p>Returns:</p> <p>Arguments</p>"},{"location":"module_docs/util/#util.config_parameters.base_strategy_parameters","title":"util.config_parameters.base_strategy_parameters","text":"<p>This file contains the available strategies and the default strategy.</p>"},{"location":"module_docs/util/#util.config_parameters.quantity_distribution_parameters","title":"util.config_parameters.quantity_distribution_parameters","text":"<p>This file contains the available data quantity distributions as well as their parameters and the default.</p>"},{"location":"module_docs/util/#util.config_parameters.feature_distribution_parameters","title":"util.config_parameters.feature_distribution_parameters","text":"<p>Contains available feature distributions and their parameters Also contains the default feature distribution</p>"},{"location":"module_docs/util/#util.config_parameters.algorithm_parameters","title":"util.config_parameters.algorithm_parameters","text":"<p>This file provides a dictionary of the available algorithms and their parameters.</p>"},{"location":"module_docs/util/#util.config_parameters.label_distribution_parameters","title":"util.config_parameters.label_distribution_parameters","text":"<p>Contains available label distributions and their parameters Also contains the default label distribution</p>"},{"location":"module_docs/util/#util.config_parameters","title":"util.config_parameters","text":"<p>This module contains the configuration parameters for the different strategies, data distributions and algorithms.</p>"},{"location":"module_docs/util/#util.config","title":"util.config","text":"<p>This module contains the Config class which is used to parse the configuration file and validate the parameters.</p>"},{"location":"module_docs/util/#util.config.Config","title":"Config Objects","text":"<pre><code>class Config()\n</code></pre> <p>This class is used to parse the configuration file and validate the parameters.</p>"},{"location":"module_docs/util/#util.config.Config.set_current_round","title":"set_current_round","text":"<pre><code>def set_current_round(i: int)\n</code></pre> <p>Sets the current round</p> <p>Arguments:</p> <ul> <li><code>i</code>: The current round</li> </ul> <p>Returns:</p> <p>None</p>"},{"location":"module_docs/util/#util.config.Config.get_current_round","title":"get_current_round","text":"<pre><code>def get_current_round()\n</code></pre> <p>Returns the current round</p> <p>Returns:</p> <p>The current round</p>"},{"location":"module_docs/util/#util.config.Config.generate_paths","title":"generate_paths","text":"<pre><code>def generate_paths(algorithm: str, dataset: str, no_clients: int)\n</code></pre> <p>Generates the paths for the output files</p> <p>Arguments:</p> <ul> <li><code>algorithm</code>: Current algorithm simulated</li> <li><code>dataset</code>: Current dataset used</li> <li><code>no_clients</code>: Number of clients used</li> </ul> <p>Returns:</p> <p>None</p>"},{"location":"module_docs/validation/","title":"Validation","text":""},{"location":"module_docs/validation/#table-of-contents","title":"Table of Contents","text":"<ul> <li>validation.evaluator</li> <li>Evaluator<ul> <li>evaluate</li> <li>generate_report</li> </ul> </li> <li>validation.validation</li> <li>Validation<ul> <li>evaluate</li> <li>generate_report</li> </ul> </li> <li>validation.training</li> <li>Training<ul> <li>generate_report</li> </ul> </li> <li>validation.datadistribution</li> <li>DataDistribution<ul> <li>evaluate</li> <li>generate_report</li> </ul> </li> </ul>"},{"location":"module_docs/validation/#validation.evaluator","title":"validation.evaluator","text":"<p>Abstract class for evaluators</p>"},{"location":"module_docs/validation/#validation.evaluator.Evaluator","title":"Evaluator Objects","text":"<pre><code>class Evaluator(ABC)\n</code></pre> <p>Abstract class for evaluators</p>"},{"location":"module_docs/validation/#validation.evaluator.Evaluator.evaluate","title":"evaluate","text":"<pre><code>def evaluate(current_run: dict)\n</code></pre> <p>Runs the evaluation if necessary, e.g. conducting a forward pass on the validation sets</p> <p>Arguments:</p> <ul> <li><code>current_run</code>: Dict containing details on the current run including dataset, no_clients</li> </ul>"},{"location":"module_docs/validation/#validation.evaluator.Evaluator.generate_report","title":"generate_report","text":"<pre><code>def generate_report()\n</code></pre> <p>Generates a report on the evaluation, needs to be run after evaluate</p>"},{"location":"module_docs/validation/#validation.validation","title":"validation.validation","text":"<p>This module contains the Validation class, which is used to evaluate the performance of a federated learning run</p>"},{"location":"module_docs/validation/#validation.validation.Validation","title":"Validation Objects","text":"<pre><code>class Validation(Evaluator)\n</code></pre>"},{"location":"module_docs/validation/#validation.validation.Validation.evaluate","title":"evaluate","text":"<pre><code>def evaluate(current_run: dict)\n</code></pre> <p>Evaluates the performance of a federated learning run</p> <p>Arguments:</p> <ul> <li><code>current_run</code>: Dictionary containing the parameters of the current run, e.g. algorithm, no_clients, etc.</li> </ul> <p>Returns:</p> <p>None</p>"},{"location":"module_docs/validation/#validation.validation.Validation.generate_report","title":"generate_report","text":"<pre><code>def generate_report()\n</code></pre> <p>Generates an HTML report with the results of the validation</p> <p>Returns:</p> <p>None</p>"},{"location":"module_docs/validation/#validation.training","title":"validation.training","text":"<p>Class for training performance evaluation</p>"},{"location":"module_docs/validation/#validation.training.Training","title":"Training Objects","text":"<pre><code>class Training(Evaluator)\n</code></pre> <p>Class for training performance evaluation</p>"},{"location":"module_docs/validation/#validation.training.Training.generate_report","title":"generate_report","text":"<pre><code>def generate_report()\n</code></pre> <p>Generates a report on the training performance  (e.g. loss, accuracy), diagrams and stores it as a .html file</p>"},{"location":"module_docs/validation/#validation.datadistribution","title":"validation.datadistribution","text":"<p>Data Distribution Evaluator</p>"},{"location":"module_docs/validation/#validation.datadistribution.DataDistribution","title":"DataDistribution Objects","text":"<pre><code>class DataDistribution(Evaluator)\n</code></pre> <p>Data Distribution Evaluator</p>"},{"location":"module_docs/validation/#validation.datadistribution.DataDistribution.evaluate","title":"evaluate","text":"<pre><code>def evaluate(current_run: dict)\n</code></pre> <p>Evaluates the data distribution</p> <p>Arguments:</p> <ul> <li><code>current_run</code>: Dict containing details on the current run including dataset, no_clients</li> </ul>"},{"location":"module_docs/validation/#validation.datadistribution.DataDistribution.generate_report","title":"generate_report","text":"<pre><code>def generate_report()\n</code></pre> <p>Generates a report on the data distribution and saves it to the output directory</p>"},{"location":"simulation/configuration/","title":"Configuration","text":"<p>The simulation can be configured in the <code>config.json</code> file. The following parameters can be set:</p> Key optional Description Min Max Default Value Example Value network_bandwidth_mean yes Mean network bandwidth to assign to clients - - 20.0 10 network_bandwidth_std yes Standard deviation of client network bandwidth - - 10.0 10 network_bandwidth_min yes Minimum network bandwidth 0.0 - 0.0 0 performance_factor_mean yes Mean performance factor (execution time multiplier) - - 1.0 1 performance_factor_std yes Standard deviation of the performance factor - - 0.2 0.2 reliability_parameter yes Parameter for the exponential distribution of reliability - - 10.0 10.0 number_of_performance_tiers yes Number of performance tiers from the <code>client_configurations.csv</code> to use 1 - 4 4 state_simulation_seed yes Seed to use in state simulation 0 - 12367123871238713871 -"},{"location":"simulation/network_bandwidth/","title":"Network Bandwidth","text":"<p>Reducing necessary communication between the client and the server is one of the main  goals of federated learning.  As such, we implemented a rudimentary network and communication simulation into SelecEval.  For this, every client is simulated as having a particular network bandwidth.  This network bandwidth is updated every round as devices move between mobile network cells or share their bandwidth with other devices.  The network bandwidth is then considered during the client runs to evaluate whether the client was able to complete the round within the given time limit. It is also included during client selection.</p> <p>The network bandwidth is modeled as a normal distribution with a mean of 20 Mbit/s and a standard deviation of 10 Mbit/s. These values are configurable by the user.</p>"},{"location":"simulation/performance_factor/","title":"Performance Factor","text":"<p>To reflect realistic device heterogeneity, we introduce a randomized performance factor that acts as a multiplier on the expected run time. By incorporating this factor, we capture the random usage patterns and energy states that prevent the devices from fully committing their computational capabilities to the training process. Applying this performance factor also significantly increases the difficulty in client selection. Even when devices with appropriate estimated execution times are selected, there is still a chance that they may not finish.</p> <p>The performance factor is modeled as a normal distribution with a mean of 1 and a standard deviation of 0.2. These values are configurable by the user.</p>"},{"location":"simulation/reliability/","title":"Client Reliability","text":"<p>Client reliability is modeled as a part of device heterogeneity. In federated learning, the server cannot control the clients. It cannot influence when clients disconnect or become unavailable for training. It could happen during the active training process on the client. This is particularly important for portable devices relying on mobile network connectivity, as they may disconnect due to challenging channel environments or coverage gaps. To model the risk of a client dropping out, we introduce a reliability score <code>r</code>. It is the probability of the client dropping out during every round. At the beginning of each training round, if selected, the client fails with the given probability. If a client drops out during one round, it will remain in the pool and may be selected again in the following round. The client reliability is generated for each client at the beginning of the simulation and remains constant throughout the run.</p> <p>The reliability score <code>r</code> is modeled as an exponential distribution with a default rate of 10. This is configurable by the user.</p>"},{"location":"validation/configuration/","title":"Configuration","text":"<p>The validation and evaluation step at the end of the simulation can be configured in the configuration file. The following parameters can be set:</p> Parameter Description Default enable_validation Enables the validation step <code>true</code> enable_data_distribution Enables the data distribution evaluation <code>true</code> device Whether to use <code>cuda</code> or <code>cpu</code> <code>cpu</code>"},{"location":"validation/output/","title":"Output","text":""},{"location":"validation/output/#output","title":"Output","text":"<p>Once a run is completed reports will be automatically included in the output folder. The reports are available as HTML files. Documentation on the individual charts that are part of the report are included in the report.</p> <p>The raw data is also included in the output folder. The data is stored in CSV and JSON Files. Methods for manual ingest of the files into pandas dataframes are included in the Advanced Analytics folder. Included here are also some example analytics scripts. These are provided as .ipynb files and require Jupyter Server to run.</p> <p>Depending on the configuration used the output folder may be very large. An example structure is provided below: <pre><code>o_20230825_123456/\n\u251c\u2500\u2500 client_output\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 client_output_FedCS_cifar10_100.json\n\u251c\u2500\u2500 data_distribution\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data_distribution_train_cifar10_100_Uniform_Dirichlet.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 data_distribution_validation_cifar10_100_Uniform_Dirichlet.csv\n\u251c\u2500\u2500 figures\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 model_output\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_output_FedCS_cifar10_100_1.pth\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 model_output_FedCS_cifar10_100_2.pth\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 State\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 state_FedCS_cifar10_100_1.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 state_FedCS_cifar10_100_2.csv\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 validation\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 validation_FedCS_cifar10_100.csv\n\u251c\u2500\u2500 data_distribution.csv\n\u251c\u2500\u2500 input_state.csv\n\u251c\u2500\u2500 working_state.csv\n\u251c\u2500\u2500 data_distribution_report.html\n\u251c\u2500\u2500 validation_report.html\n\u251c\u2500\u2500 training_performance.html\n</code></pre></p>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/","title":"Generate Data Distribution Heatmaps","text":"<p>This notebook provides code for generating a data distribution heatmap from the files in the data_distribution  folder.</p>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/#imports","title":"Imports","text":"<pre><code>from os import listdir\nfrom os.path import isfile, join\nfrom statistics import fmean\n\nimport pandas as pd\nfrom matplotlib import cm\nfrom matplotlib.colors import Normalize\n\npd.options.mode.chained_assignment = None  # default='warn'\nimport json\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport seaborn as sns\n</code></pre>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/#file-loading","title":"File loading","text":"<pre><code>file_list = [f for f in listdir(\"outputs\") if isfile(join(\"outputs\", f))]\ndfs = []\nfor i in range(len(file_list)):\n    fname = \"outputs/\" + file_list[i]\n    df_temp = pd.read_csv(fname)\n    df_temp.set_index(['client'], inplace=True)\n    df_temp['run'] = file_list[i].replace(\".csv\", \"\")\n    dfs.append(df_temp)\ndf = pd.concat(dfs).reset_index()\n</code></pre>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/#dataframe-preparation","title":"Dataframe preparation","text":"<pre><code>df = df.melt(id_vars=[\"client\", \"run\"], var_name=\"class\").fillna(0)\ndf['run'] = df['run'].astype(\"category\")\n</code></pre>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/#wrapper-for-drawing-the-heatmaps","title":"Wrapper for drawing the heatmaps","text":"<pre><code>def draw_heatmap(*args, **kwargs):\n    data = kwargs.pop('data')\n    d = data.pivot(index=args[0], columns=args[1], values=args[2])\n    sns.heatmap(d, **kwargs)\n</code></pre>"},{"location":"validation/advanced_analytics/data_distribution_heatmap/#plotting","title":"Plotting","text":"<pre><code>mpl.rcParams['font.family'] = \"serif\"\nmpl.rcParams['font.serif'] = \"Charter\"\nsns.set_style(\"ticks\")\nsns.set_theme(font=\"Charter\")\ng = sns.FacetGrid(df, col=\"run\", col_wrap=2, sharey=True, sharex=True, xlim=(0.5,1.0), height=7, aspect=1)\ncbar_ax = g.fig.add_axes([1, .15, .03, .7])\n\ng.map_dataframe(draw_heatmap, 'client', 'class', 'value', cbar=True, square = False, vmin=0, vmax=400, cmap='viridis', cbar_ax=cbar_ax)\ncbar_ax.set_ylabel(\"Number of samples\", fontproperties={'family': 'Charter'},fontsize='x-large')\ng.set_xlabels(\"Class\", fontproperties={'family': 'Charter'},fontsize='x-large')\ng.set_ylabels(\"Clients\", fontproperties={'family': 'Charter'},fontsize='x-large')\ng.fig.subplots_adjust(top=0.95)\naxs = g.axes_dict\ng.fig.suptitle(\"Supported Data Label Distributions\", fontsize='xx-large', fontproperties={'family': 'Charter'})\ng.show()\n</code></pre> <pre><code>/home/jsteimle/anaconda3/envs/Flower/lib/python3.11/site-packages/seaborn/axisgrid.py:118: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n  self._figure.tight_layout(*args, **kwargs)\n</code></pre>"},{"location":"validation/advanced_analytics/different_accuracy_metrics/","title":"Accuracy Metrics","text":""},{"location":"validation/advanced_analytics/different_accuracy_metrics/#imports","title":"Imports","text":"<pre><code>import pandas as pd\nfrom os import listdir, getcwd\nfrom os.path import isfile, join\n</code></pre>"},{"location":"validation/advanced_analytics/different_accuracy_metrics/#data-import","title":"Data import","text":"<p>This notebook can be used to compute and average results across multiple runs, simply adapt the run_folders.</p> <pre><code>run_folders = ['run_1']\n</code></pre> <pre><code>dfs = []\nfor folder in run_folders:\n    run_folder = folder + \"/validation/\"\n    file_list = [f for f in listdir(run_folder) if isfile(join(run_folder, f))]\n    print(\"Loaded\", file_list, \"from\", run_folder)\n    for i in range(len(file_list)):\n        fname = run_folder + file_list[i]\n        df_temp = pd.read_csv(fname)\n        df_temp[\"src\"] = file_list[i].replace(\".csv\", \"\")\n        df_temp[\"run\"] = folder\n        dfs.append(df_temp)\ndf = pd.concat(dfs)\n</code></pre> <pre><code>Loaded ['ActiveFL.csv', 'CEP.csv', 'Random.csv', 'FedCS.csv', 'PowD.csv'] from run_1/validation/\n</code></pre>"},{"location":"validation/advanced_analytics/different_accuracy_metrics/#preview-of-the-imported-data","title":"Preview of the imported data","text":"<pre><code>df.sample(5)\n</code></pre> round client loss acc total correct class_accuracy src run 12199 24 humongous-rating 0.031195 0.725490 51 37 [0.8571428656578064, 1.0, 0.5, 0.4000000059604... Random run_1 4852 9 seething-tambourine 0.056867 0.450980 51 23 [0.3333333432674408, 1.0, 1.0, 0.3333333432674... CEP run_1 9348 18 square-lien 0.042600 0.568627 51 29 [0.8333333134651184, 0.875, 1.0, 0.0, 0.333333... Random run_1 8055 16 kinetic-kern 0.035176 0.745098 51 38 [0.6666666865348816, 1.0, 0.800000011920929, 0... PowD run_1 3443 6 few-body 0.052351 0.509804 51 26 [0.75, 0.8333333134651184, 0.6666666865348816,... FedCS run_1"},{"location":"validation/advanced_analytics/different_accuracy_metrics/#generate-mean-min-and-max-accuracy-after-the-final-round","title":"Generate Mean, Min and Max Accuracy after the final round","text":""},{"location":"validation/advanced_analytics/different_accuracy_metrics/#aggregation-per-run","title":"Aggregation per Run","text":"<pre><code>df_gen = df[df['round'] == max(df['round'])][['src', 'run', 'acc']]\ndf_gen_max = df_gen.groupby(['src', 'run']).max()\ndf_gen_max['op'] = 'Top-1'\ndf_gen_mean = df_gen.groupby(['src', 'run']).mean()\ndf_gen_mean['op'] = 'Mean'\ndf_gen_min = df_gen.groupby(['src', 'run']).min()\ndf_gen_min['op'] = 'Bottom-1'\ndf_gen = pd.concat([df_gen_max, df_gen_mean, df_gen_min])\ndf_gen = df_gen.pivot(columns=\"op\")\ndf_gen\n</code></pre> acc op Bottom-1 Mean Top-1 src run ActiveFL run_1 0.568627 0.735216 0.901961 CEP run_1 0.588235 0.743725 0.901961 FedCS run_1 0.549020 0.740392 0.921569 PowD run_1 0.568627 0.731216 0.882353 Random run_1 0.568627 0.740000 0.901961"},{"location":"validation/advanced_analytics/different_accuracy_metrics/#final-aggregation","title":"Final Aggregation","text":"<pre><code>df_output = df_gen.groupby('src').mean()\ndf_output\n</code></pre> acc op Bottom-1 Mean Top-1 src ActiveFL 0.568627 0.735216 0.901961 CEP 0.588235 0.743725 0.901961 FedCS 0.549020 0.740392 0.921569 PowD 0.568627 0.731216 0.882353 Random 0.568627 0.740000 0.901961"},{"location":"validation/advanced_analytics/different_accuracy_metrics/#time-to-accuracy","title":"Time to Accuracy","text":""},{"location":"validation/advanced_analytics/different_accuracy_metrics/#generate-time-to-accuracy-mean","title":"Generate Time to Accuracy (Mean)","text":"<pre><code>df_gen = df[['round', 'src', 'run', 'acc']]\naccuracy_steps = [0.2,0.3,0.4,0.5,0.6,0.7,0.8]\ndf_res = []\nfor algorithm in df['src'].unique():\n    result = {}\n    for step in accuracy_steps:\n        df_tmp = df_gen[df_gen['src'] == algorithm][['round', 'acc', 'run']].groupby(['round', 'run']).mean().reset_index()\n        df_tmp = df_tmp[df_tmp['acc'] &gt;= step]\n        if len(df_tmp) == 0:\n            result[step] = '-'\n        else:\n            df_temp = df_tmp[['round', 'run']].groupby('run').min().reset_index()\n            result[step] = df_temp['round'].mean()\n    df_res.append(pd.DataFrame(result,index=[algorithm]))\ndf_res = pd.concat(df_res)\ndf_res.columns = [\"{:.2f}\".format(x) for x in df_res.columns]\ndf_res\n</code></pre> 0.20 0.30 0.40 0.50 0.60 0.70 0.80 ActiveFL 4.0 5.0 7.0 9.0 13.0 25.0 - CEP 4.0 5.0 7.0 9.0 14.0 23.0 - Random 3.0 4.0 6.0 7.0 12.0 22.0 - FedCS 3.0 5.0 6.0 9.0 13.0 23.0 - PowD 4.0 4.0 6.0 8.0 14.0 24.0 -"},{"location":"validation/advanced_analytics/different_fairness_metrics/","title":"Fairness metrics","text":""},{"location":"validation/advanced_analytics/different_fairness_metrics/#imports","title":"Imports","text":"<pre><code>import pandas as pd\nfrom os import listdir, getcwd\nfrom os.path import isfile, join\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport ast\n</code></pre>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#data-import","title":"Data import","text":"<p>The import script is designed to import and average multiple runs. You can adjust your run folders accordingly.</p> <pre><code>run_folders = ['run_1']\n</code></pre> <pre><code>dfs = []\nfor folder in run_folders:\n    run_folder = folder + \"/validation/\"\n    file_list = [f for f in listdir(run_folder) if isfile(join(run_folder, f))]\n    print(\"Loaded\", file_list, \"from\", run_folders)\n    for i in range(len(file_list)):\n        fname = run_folder + file_list[i]\n        df_temp = pd.read_csv(fname)\n        df_temp[\"src\"] = file_list[i].replace(\".csv\", \"\")\n        df_temp[\"run\"] = folder\n        dfs.append(df_temp)\ndf = pd.concat(dfs)\n</code></pre> <pre><code>Loaded ['ActiveFL.csv', 'CEP.csv', 'Random.csv', 'FedCS.csv', 'PowD.csv'] from ['run_1']\n</code></pre>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#dataframe-preview","title":"Dataframe Preview","text":"<pre><code>df\n</code></pre> round client loss acc total correct class_accuracy src run 0 0 burning-field NaN 0.117647 51 6 [0.11764705926179886, 0.0, 0.0, 0.0, 0.0, 0.0,... ActiveFL run_1 1 0 buoyant-eaves NaN 0.117647 51 6 [0.11764705926179886, 0.0, 0.0, 0.0, 0.0, 0.0,... ActiveFL run_1 2 0 deafening-adhesive NaN 0.117647 51 6 [0.11764705926179886, 0.0, 0.0, 0.0, 0.0, 0.0,... ActiveFL run_1 3 0 swarm-canity NaN 0.117647 51 6 [0.11764705926179886, 0.0, 0.0, 0.0, 0.0, 0.0,... ActiveFL run_1 4 0 amiable-wolverine NaN 0.117647 51 6 [0.11764705926179886, 0.0, 0.0, 0.0, 0.0, 0.0,... ActiveFL run_1 ... ... ... ... ... ... ... ... ... ... 14995 29 cold-reef 0.026430 0.745098 51 38 [0.8333333134651184, 1.0, 0.6666666865348816, ... PowD run_1 14996 29 blue-bat 0.036713 0.686275 51 35 [1.0, 1.0, 1.0, 0.4285714328289032, 0.33333334... PowD run_1 14997 29 damp-actuary 0.035672 0.627451 51 32 [1.0, 0.8888888955116272, 0.6000000238418579, ... PowD run_1 14998 29 local-yield 0.025788 0.745098 51 38 [0.8333333134651184, 0.8888888955116272, 0.857... PowD run_1 14999 29 vivid-certificate 0.040833 0.607843 51 31 [0.75, 1.0, 0.5, 0.3333333432674408, 0.5, 0.66... PowD run_1 <p>75000 rows \u00d7 9 columns</p>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#client-fairness","title":"Client Fairness","text":""},{"location":"validation/advanced_analytics/different_fairness_metrics/#final-round-fairness-histograms","title":"Final Round Fairness Histograms","text":"<pre><code>df_plot = df[df['round'] == max(df['round'])][['acc', 'src', 'client']]\nplt.figure(figsize=(7,4), dpi=1200)\nsns.set_style(\"ticks\")\ng = sns.FacetGrid(df_plot, col=\"src\", col_wrap=3, sharey='row', sharex=False, xlim=(0.5,1.0))\ng.map(sns.histplot, \"acc\", bins=10, binwidth=0.02, palette=\"Set2\", hue=len(df.index))\ng.set_titles(\"{col_name}\")\nfor (row, col, hue_idx), data in g.facet_data():\n    if not data.values.size:\n        continue\n    ax = g.facet_axis(row, col)\n    ax.axvline(data[\"acc\"].mean(), c=\"k\", ls=\"-\", lw=1, label=\"Mean\")\n    ax.axvline(data[\"acc\"].quantile(.1), c=\"orange\", ls=\"-\", lw=1)\n    ax.axvline(data[\"acc\"].quantile(.75), c=\"orange\", ls=\"-\", lw=1)\nplt.show()\n</code></pre>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#fairness-boxplots","title":"Fairness Boxplots","text":"<pre><code>df_plot = df[df['round'] == max(df['round'])][['acc', 'src', 'client']]\ndf_plot = df_plot.groupby([\"client\", \"src\"]).mean().reset_index()\nplt.figure(figsize=(7,4), dpi=1200)\nsns.set_style(\"ticks\")\nplt.rcParams['font.family'] = \"serif\"\nplt.rcParams['font.serif'] = \"Charter\"\nax = sns.boxplot(df_plot, x='acc', y='src', palette=\"Set2\")\nax.set_xlabel(\"Accuracy\")\nax.set_ylabel(\"Strategy\")\nax.set_title(\"Accuracy Distribution for different Selection Algorithms\", fontsize=\"x-large\")\nplt.show()\n</code></pre>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#class-fairness","title":"Class Fairness","text":""},{"location":"validation/advanced_analytics/different_fairness_metrics/#define-cifar-10-classes","title":"Define CIFAR-10 Classes","text":"<pre><code>classes = (\n            \"plane\",\n            \"car\",\n            \"bird\",\n            \"cat\",\n            \"deer\",\n            \"dog\",\n            \"frog\",\n            \"horse\",\n            \"ship\",\n            \"truck\",\n        )\n</code></pre>"},{"location":"validation/advanced_analytics/different_fairness_metrics/#class-accuracy-plots","title":"Class Accuracy Plots","text":"<pre><code>df_plot = df[df['round'] == max(df['round'])][['class_accuracy', 'src', 'run']]\ndf_plot['class_accuracy']=df_plot['class_accuracy'].apply(lambda x: ast.literal_eval(x))\ndf_temps = []\nfor i in df_plot['src'].unique():\n    df_temp = pd.DataFrame(df_plot[df_plot['src'] == i]['class_accuracy'].to_list(), columns=classes)\n    df_temp['src'] = i\n    df_temps.append(df_temp)\ndf_plot = pd.concat(df_temps).groupby(['src']).mean().reset_index()\ndf_plot = df_plot.melt(id_vars=['src'], var_name='class', value_name='acc')\ndf_plot['class'] = df_plot['class'].astype('category')\ndf_plot['color'] = 1\n\nplt.figure(figsize=(7,4), dpi=1200)\nsns.set_style(\"ticks\")\nplt.rcParams['font.family'] = \"serif\"\nplt.rcParams['font.serif'] = \"Charter\"\naxs = sns.catplot(\n    df_plot, x=\"class\", y='acc', col=\"src\", height=3, aspect=2, col_wrap=2,\n    kind=\"bar\", margin_titles=True, palette=\"Set2\", legend=None, sharex=False\n)\naxs.set_titles(\"{col_name}\")\naxs.set_xlabels(\"Class\")\naxs.set_ylabels(\"Mean Accuracy\")\naxs.fig.suptitle(\"Per Class Accuracy for different Selection Approaches\", fontsize='xx-large', fontproperties={'family': 'Charter'})\naxs.fig.subplots_adjust(top=0.9)\nplt.show()\n</code></pre>"},{"location":"validation/advanced_analytics/different_training_metrics/","title":"Training Failure Metrics","text":""},{"location":"validation/advanced_analytics/different_training_metrics/#imports","title":"Imports","text":"<pre><code>import pandas as pd\nfrom os import listdir, getcwd\nfrom os.path import isfile, join\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport json\nimport numpy as np\nimport itertools\nimport matplotlib.patches as mpatches\npd.options.mode.chained_assignment = None  # default='warn'\n</code></pre>"},{"location":"validation/advanced_analytics/different_training_metrics/#data-import","title":"Data Import","text":"<p>This notebook can be used to compute and average results across multiple runs, simply adapt the run_folders.</p> <pre><code>run_folders = ['run_1']\n</code></pre> <pre><code>dfs = []\nfor folder in run_folders:\n    run_folder = folder + \"/client_output/\"\n    file_list = [f for f in listdir(run_folder) if isfile(join(run_folder, f))]\n    print(\"Loaded\", file_list, \"from\", run_folder)\n    for i in range(len(file_list)):\n        file_dfs = []\n        with open(run_folder + file_list[i]) as f:\n            for line in f.readlines():\n                json_data = pd.json_normalize(json.loads(line))\n                file_dfs.append(json_data)\n        file_df = pd.concat(file_dfs)\n        file_df[\"src\"] = file_list[i].replace(\".json\", \"\")\n        file_df[\"run\"] = folder\n        dfs.append(file_df)\ndf = pd.concat(dfs)\n</code></pre> <pre><code>Loaded ['Random.json', 'FedCS.json', 'ActiveFL.json', 'PowD.json', 'CEP.json'] from run_1/client_output/\n</code></pre>"},{"location":"validation/advanced_analytics/different_training_metrics/#dataset-preparation","title":"Dataset Preparation","text":"<pre><code>df['server_round'] = np.where(df['server_round'] == max(df['server_round']), 0, df['server_round'])\n</code></pre> <pre><code>df['reason'] = df['reason'].fillna(\"success\")\n</code></pre>"},{"location":"validation/advanced_analytics/different_training_metrics/#dataframe-preview","title":"DataFrame Preview","text":"<pre><code>df.sample(2)\n</code></pre> server_round client_name actual_execution_time execution_time upload_time total_time status current_timestamp state.cpu state.ram ... state.performance_tier state.expected_execution_time state.i_performance_factor state.client_name train_output.accuracy train_output.avg_epoch_loss train_output.no_samples reason src run 0 1 slow-sump NaN 88.0 49.450109 120.000000 fail 2023-08-11 16:04:18.782893 8 32 ... 2 80 1.10 slow-sump NaN NaN NaN timeout failure Random run_1 0 10 level-platform 1.203034 92.0 14.012158 106.012158 success 2023-08-11 17:53:05.487195 8 32 ... 2 80 1.15 level-platform [0.44468546637744033, 0.7613882863340564, 0.91... [0.05063865914003451, 0.025299487623371943, 0.... 15.0 success ActiveFL run_1 <p>2 rows \u00d7 22 columns</p>"},{"location":"validation/advanced_analytics/different_training_metrics/#generate-average-failures-per-round-table","title":"Generate average failures per round table","text":"<pre><code>df_gen = df[['server_round', 'src', 'run', 'reason']]\ndf_gen = df_gen.groupby(['src', 'reason', 'run']).count()\ndf_gen['server_round'] = df_gen['server_round'] / 30\ndf_gen = df_gen.groupby(['src', 'reason']).mean().reset_index()\ndf_gen = df_gen.pivot_table(index=\"src\",columns=\"reason\", values=\"server_round\").reset_index() \ndf_gen['Total Failures'] = df_gen['reliability failure'] + df_gen['timeout failure']\ndf_gen['Total Clients'] = df_gen['Total Failures'] + df_gen['success']\ndf_gen['Total Clients'] = df_gen['Total Clients'].astype(int)\ndf_gen.columns = ['Strategy', 'Reliability Failures', 'Successful Participations', 'Timeout Failures', 'Total Failures', 'Total Clients']\ncols = ['Strategy', 'Successful Participations', 'Reliability Failures', 'Timeout Failures', 'Total Failures', 'Total Clients']\ndf_gen = df_gen[cols]\ndf_gen\n# df_gen.to_latex('mean_failures_per_round.tex',\n#                   formatters={\"name\": \"{:.2f}\".format},\n#                   float_format=\"{:.2f}\".format,\n#                    index=None)\n</code></pre> Strategy Successful Participations Reliability Failures Timeout Failures Total Failures Total Clients 0 ActiveFL 18.233333 5.800000 25.966667 31.766667 50 1 CEP 38.833333 5.566667 5.600000 11.166667 50 2 FedCS 24.000000 5.333333 20.666667 26.000000 50 3 PowD 20.166667 4.266667 25.566667 29.833333 50 4 Random 21.266667 5.233333 23.500000 28.733333 50"},{"location":"validation/advanced_analytics/different_training_metrics/#failures-per-round-diagram","title":"Failures per Round Diagram","text":"<pre><code>nice_name_map = {'reliability failure': 'Reliability Failure', 'timeout failure':'Timeout', 'success': 'Successful Completion'}\ndf_gen = df[['server_round', 'src', 'run', 'reason']]\ndf_gen['reason'] = df_gen['reason'].apply(lambda x: nice_name_map[x])\ndf_gen = df_gen.groupby(['src', 'reason', 'run']).count()\ndf_gen['server_round'] = df_gen['server_round'] / len(df['server_round'].unique())\ndf_gen = df_gen.groupby(['src', 'reason']).mean().reset_index()\ndf_gen['Status'] = pd.Categorical(df_gen['reason'], ['Reliability Failure', 'Timeout', 'Successful Completion'])\ndf_gen\n</code></pre> src reason server_round Status 0 ActiveFL Reliability Failure 5.800000 Reliability Failure 1 ActiveFL Successful Completion 18.233333 Successful Completion 2 ActiveFL Timeout 25.966667 Timeout 3 CEP Reliability Failure 5.566667 Reliability Failure 4 CEP Successful Completion 38.833333 Successful Completion 5 CEP Timeout 5.600000 Timeout 6 FedCS Reliability Failure 5.333333 Reliability Failure 7 FedCS Successful Completion 24.000000 Successful Completion 8 FedCS Timeout 20.666667 Timeout 9 PowD Reliability Failure 4.266667 Reliability Failure 10 PowD Successful Completion 20.166667 Successful Completion 11 PowD Timeout 25.566667 Timeout 12 Random Reliability Failure 5.233333 Reliability Failure 13 Random Successful Completion 21.266667 Successful Completion 14 Random Timeout 23.500000 Timeout <pre><code>plt.figure(figsize=(7,4), dpi=1200)\nsns.set_style(\"ticks\")\nplt.rcParams['font.family'] = \"serif\"\nplt.rcParams['font.serif'] = \"Charter\"\nax = sns.histplot(x = 'src', hue = 'Status',multiple = 'stack', weights=\"server_round\", data=df_gen,shrink = 0.7, palette=\"Set2\")\nax.set_xlabel(\"Client Selection Strategy\")\nax.set_ylabel(\"Average Number of Clients per Round\")\nno_status = 5\nhatches = itertools.cycle(['///', '\\\\\\\\\\\\', 'XXX'])\nfor i, bar in enumerate(ax.patches):\n    if i % no_status == 0:\n         hatch = next(hatches)\n    bar.set_hatch(hatch)\ncolors = sns.color_palette(\"Set2\")\ncirc1 = mpatches.Patch(facecolor=colors[2], hatch='////',label='Successful Completions')\ncirc2= mpatches.Patch(facecolor=colors[1], hatch=r'\\\\\\\\',label='Timeout Failures')\ncirc3 = mpatches.Patch(facecolor=colors[0], hatch='XXX',label='Reliability Failures')\n\nax.legend(handles = [circ1,circ2,circ3],loc=0)\nax.set_title(\"Average Number of Client Failures per Round\", fontsize='x-large')\nplt.show()\n</code></pre>"},{"location":"validation/advanced_analytics/loading_raw_files/","title":"Loading Raw Files","text":""},{"location":"validation/advanced_analytics/loading_raw_files/#overview","title":"Overview","text":"<p>The output of each run contains raw files that can be included in further analytics.  The following snippets allows the reading of multiple output files and stores them in a single pandas dataframe.</p>"},{"location":"validation/advanced_analytics/loading_raw_files/#loading-validation-results","title":"Loading Validation Results","text":"<pre><code>import pandas as pd\nfrom os import listdir, getcwd\nfrom os.path import isfile, join\nrun_folders = ['run_1', 'run_2', 'run_3']\ndfs = []\nfor folder in run_folders:\n    run_folder = folder + \"/validation/\"\n    file_list = [f for f in listdir(run_folder) if isfile(join(run_folder, f))]\n    print(\"Loaded\", file_list, \"from\", run_folder)\n    for i in range(len(file_list)):\n        fname = run_folder + file_list[i]\n        df_temp = pd.read_csv(fname)\n        df_temp[\"src\"] = file_list[i].replace(\".csv\", \"\")\n        df_temp[\"run\"] = folder\n        dfs.append(df_temp)\ndf = pd.concat(dfs)\ndf\n</code></pre>"},{"location":"validation/advanced_analytics/loading_raw_files/#loading-training-output","title":"Loading Training Output","text":"<pre><code>import pandas as pd\nfrom os import listdir, getcwd\nfrom os.path import isfile, join\nimport json\nrun_folders = ['run_1', 'run_2', 'run_3']\ndfs = []\nfor folder in run_folders:\n    run_folder = folder + \"/client_output/\"\n    file_list = [f for f in listdir(run_folder) if isfile(join(run_folder, f))]\n    print(\"Loaded\", file_list, \"from\", run_folder)\n    for i in range(len(file_list)):\n        file_dfs = []\n        with open(run_folder + file_list[i]) as f:\n            for line in f.readlines():\n                json_data = pd.json_normalize(json.loads(line))\n                file_dfs.append(json_data)\n        file_df = pd.concat(file_dfs)\n        file_df[\"src\"] = file_list[i].replace(\".json\", \"\")\n        file_df[\"run\"] = folder\n        dfs.append(file_df)\ndf = pd.concat(dfs)\n</code></pre>"},{"location":"validation/advanced_analytics/loading_raw_files/#loading-data-distribution","title":"Loading Data Distribution","text":"<pre><code>import pandas as pd\nfrom os import listdir\nfrom os.path import isfile, join\nfile_list = [f for f in listdir(\"outputs\") if isfile(join(\"outputs\", f))]\ndfs = []\nfor i in range(len(file_list)):\n    fname = \"outputs/\" + file_list[i]\n    df_temp = pd.read_csv(fname)\n    df_temp.set_index(['client'], inplace=True)\n    df_temp['run'] = file_list[i].replace(\".csv\", \"\")\n    dfs.append(df_temp)\ndf = pd.concat(dfs).reset_index()\n</code></pre>"}]}